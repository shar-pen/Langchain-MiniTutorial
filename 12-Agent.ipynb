{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool\n",
    "\n",
    "工具是一个接口，允许代理、链条或大语言模型与外部世界互动。\n",
    "\n",
    "LangChain 提供了易于使用的内置工具，并且还允许用户轻松构建自定义工具。\n",
    "\n",
    "**你可以在下面的链接中找到集成到 LangChain 中的工具列表。**\n",
    "\n",
    "- [集成到 LangChain 中的工具列表](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内置工具 Built-in tools\n",
    "\n",
    "你可以使用 LangChain 提供的预定义工具和工具包。\n",
    "\n",
    "工具指的是单一的实用工具，而工具包将多个工具组合成一个单元供使用。\n",
    "\n",
    "你可以在下面的链接中找到相关的工具。\n",
    "\n",
    "**注意**\n",
    "- [LangChain 工具/工具包](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web 检索工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片生成工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(\n",
    "\tbase_url='http://localhost:5551/v1',\n",
    "\tapi_key='EMPTY',\n",
    "\tmodel_name='Qwen2.5-7B-Instruct',\n",
    "\ttemperature=0.2,\n",
    ")\n",
    "\n",
    "# Define a prompt template for DALL-E image generation\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\n",
    "    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\n",
    "    \"Output should be less than 1000 characters. Write in English only.\"\n",
    "    \"Image Description: \\n{image_desc}\",\n",
    ")\n",
    "\n",
    "# Create a chain connecting the prompt, LLM, and output parser\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Execute the chain\n",
    "image_prompt = chain.invoke(\n",
    "    {\"image_desc\": \"A Neo-Classicism painting satirizing people looking at their smartphones.\"}\n",
    ")\n",
    "\n",
    "# Output the image prompt\n",
    "print(image_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几乎所有 tool 都是需要 api key 的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python REPL 工具\n",
    "\n",
    "此工具提供一个类，用于在 **REPL (Read-Eval-Print Loop)** 环境中执行 Python 代码。\n",
    "- [PythonREPLTool](https://python.langchain.com/docs/integrations/tools/python/)\n",
    "\n",
    "**描述**\n",
    "\n",
    "- 提供一个 Python shell 环境。\n",
    "- 执行有效的 Python 命令作为输入。\n",
    "- 使用 `print(...)` 函数查看结果。\n",
    "\n",
    "**主要特点**\n",
    "\n",
    "- sanitize_input：可选项，用于清理输入（默认：True）\n",
    "- python_repl：**PythonREPL** 的实例（默认：在全局作用域中执行）\n",
    "\n",
    "**使用方法**\n",
    "\n",
    "- 创建 `PythonREPLTool` 的实例。\n",
    "- 使用 `run`、`arun` 或 `invoke` 方法执行 Python 代码。\n",
    "\n",
    "**输入清理**\n",
    "\n",
    "- 从输入字符串中移除不必要的空格、反引号、关键字 \"python\" 和其他多余的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# Creates a tool for executing Python code.\n",
    "python_tool = PythonREPLTool()\n",
    "\n",
    "# Executes Python code and returns the results.\n",
    "print(python_tool.invoke(\"print(100 + 200)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是请求大语言模型编写 Python 代码并返回结果的示例。\n",
    "\n",
    "**工作流程概述**\n",
    "1. 请求大语言模型为特定任务编写 Python 代码。\n",
    "2. 执行生成的代码以获取结果。\n",
    "3. 输出结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "python_tool = PythonREPLTool()\n",
    "# A function that executes Python code, outputs intermediate steps, and returns the tool execution results.\n",
    "def print_and_execute(code, debug=True):\n",
    "    if debug:\n",
    "        print(\"CODE:\")\n",
    "        print(code)\n",
    "    return python_tool.invoke(code)\n",
    "\n",
    "\n",
    "# A prompt requesting Python code to be written.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. \"\n",
    "            \"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "# Create LLM model.\n",
    "llm = ChatOpenAI(\n",
    "\tbase_url='http://localhost:5551/v1',\n",
    "\tapi_key='EMPTY',\n",
    "\tmodel_name='Qwen2.5-7B-Instruct',\n",
    "\ttemperature=0.2,\n",
    ")\n",
    "\n",
    "# Create a chain using the prompt and the LLM model.\n",
    "chain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)\n",
    "\n",
    "# Outputting the results.\n",
    "print(chain.invoke(\"Write code to generate Powerball numbers.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义工具\n",
    "\n",
    "除了 LangChain 提供的内置工具外，你还可以定义和使用自己的自定义工具。\n",
    "\n",
    "为此，可以使用 `langchain.tools` 模块提供的 `@tool` 装饰器将一个函数转换为工具。\n",
    "\n",
    "@tool 装饰器: 这个装饰器允许你将一个函数转换为工具。它提供了各种选项来定制工具的行为。\n",
    "\n",
    "**使用方法**\n",
    "1. 在函数上方应用 `@tool` 装饰器。\n",
    "2. 根据需要设置装饰器参数。\n",
    "\n",
    "使用这个装饰器，你可以轻松地将常规 Python 函数转换为强大的工具，从而实现自动化文档生成和灵活的接口创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# Convert a function into a tool using a decorator.\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Execute tool.\n",
    "print(add_numbers.invoke({\"a\": 3, \"b\": 4}))\n",
    "print(multiply_numbers.invoke({\"a\": 3, \"b\": 4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个用于 Google 新闻文章搜索的自定义工具\n",
    "\n",
    "定义 `GoogleNews` 类，该类将作为一个工具，用于搜索 Google 新闻文章。\n",
    "\n",
    "**注意**\n",
    "- 不需要 API 密钥（因为它使用 RSS 源）。\n",
    "\n",
    "此工具用于搜索由 **news.google.com** 提供的新闻文章。\n",
    "\n",
    "**描述**\n",
    "- 使用 Google 新闻搜索 API 来检索最新的新闻。\n",
    "- 允许基于关键词搜索新闻。\n",
    "\n",
    "**主要参数**\n",
    "- `k` (int)：返回的最大搜索结果数（默认：5）。\n",
    "\n",
    "```python\n",
    "# hl: 语言, gl: 区域, ceid: 区域和语言代码\n",
    "url = f\"{self.base_url}?hl=en&gl=US&ceid=US:en\" \n",
    "```\n",
    "\n",
    "在代码中，你可以通过修改语言 (hl)、区域 (gl) 和区域与语言代码 (ceid) 来调整搜索结果的语言和区域。\n",
    "\n",
    "**注意**\n",
    "\n",
    "将提供的代码保存为 `google_news.py`，然后你可以在其他文件中使用 `from google_news import GoogleNews` 进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from urllib.parse import quote\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "class GoogleNews:\n",
    "    \"\"\"\n",
    "    This is a class for searching Google News and returning the results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the GoogleNews class.\n",
    "        Sets the base_url attribute.\n",
    "        \"\"\"\n",
    "        self.base_url = \"https://news.google.com/rss\"\n",
    "\n",
    "    def _fetch_news(self, url: str, k: int = 3) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Fetches news from the given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to fetch the news from.\n",
    "            k (int): The maximum number of news articles to fetch (default: 3).\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing news titles and links.\n",
    "        \"\"\"\n",
    "        news_data = feedparser.parse(url)\n",
    "        return [\n",
    "            {\"title\": entry.title, \"link\": entry.link}\n",
    "            for entry in news_data.entries[:k]\n",
    "        ]\n",
    "\n",
    "    def _collect_news(self, news_list: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Formats and returns the list of news articles.\n",
    "\n",
    "        Args:\n",
    "            news_list (List[Dict[str, str]]): A list of dictionaries containing news information.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing URLs and content.\n",
    "        \"\"\"\n",
    "        if not news_list:\n",
    "            print(\"No news available for the given keyword.\")\n",
    "            return []\n",
    "\n",
    "        result = []\n",
    "        for news in news_list:\n",
    "            result.append({\"url\": news[\"link\"], \"content\": news[\"title\"]})\n",
    "\n",
    "        return result\n",
    "\n",
    "    def search_latest(self, k: int = 3) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Searches for the latest news.\n",
    "\n",
    "        Args:\n",
    "            k (int): The maximum number of news articles to search for (default: 3).\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing URLs and content.\n",
    "        \"\"\"\n",
    "        #url = f\"{self.base_url}?hl=ko&gl=KR&ceid=KR:ko\"\n",
    "        url = f\"{self.base_url}?hl=en&gl=US&ceid=US:en\" # hl: 언어, gl: 지역, ceid: 지역 및 언어 코드\n",
    "        news_list = self._fetch_news(url, k)\n",
    "        return self._collect_news(news_list)\n",
    "\n",
    "    def search_by_keyword(\n",
    "        self, keyword: Optional[str] = None, k: int = 3\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Searches for news using a keyword.  \n",
    "\n",
    "        Args:\n",
    "            keyword (Optional[str]): The keyword to search for (default: None).\n",
    "            k (int): The maximum number of news articles to search for (default: 3).\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing URLs and content.\n",
    "        \"\"\"\n",
    "        if keyword:\n",
    "            encoded_keyword = quote(keyword)\n",
    "            url = f\"{self.base_url}/search?q={encoded_keyword}\"\n",
    "        else:\n",
    "            url = f\"{self.base_url}?hl=en&gl=US&ceid=US:en\"\n",
    "        news_list = self._fetch_news(url, k)\n",
    "        return self._collect_news(news_list)\n",
    "\n",
    "\n",
    "google_tool = GoogleNews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_tool.search_by_keyword(\"AI Investment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "地址是 google 的, 得翻墙, 以下是示例结果  \n",
    "[{'url': 'https://news.google.com/rss/articles/CBMimAFBVV95cUxPNkFrLURMdEZWOV9zdmRrTUhNbVFkdWswZWx2Qmh4cTJlMmFIdmpsQ3doaVluenA3TEJaT0U3RWVmanl3TTQ5V3RfS3kyYVpydEloNWZXbjBmSF85MGR5cjNFSFI5eFhtTGdIVlNXX3UxNmxwMnVIb2NkTXA5WFVZR2hKLUw5RU9iT3k1Zno2UG10N2h1b2g5Sw?oc=5',\n",
    "  'content': 'Nvidia Calls China\\'s DeepSeek an \"Excellent AI Advancement\": Should Investors Press the Buy Button? - The Motley Fool'},\n",
    " {'url': 'https://news.google.com/rss/articles/CBMikwFBVV95cUxPd2ZnMnNwSWo2ZGhVSUJuNHd5S1Y3WUNWSkM4a0h5aHZQWU8tdzdlaW9pb25RUnI2cEwyZGtTemo5VUgwTDNHLVppNkw2MXdsbTRnb0UteHhtaHgxV043ZE9ZeG5aLUlCTzBGSHc1TFJzaHJsZENObzMxdTlvaEcyaG9vSjlRSTFWYXJEelF6RkRETnc?oc=5',\n",
    "  'content': 'How DeepSeek is upending AI innovation and investment after sending tech leaders reeling - New York Post'},\n",
    " {'url': 'https://news.google.com/rss/articles/CBMivwFBVV95cUxNUGdjLVE5dFpLaVZOcFY1djBRQXBLeTNZalptNmstNXlWRkpvX1U2aTJ5cDNiS3RNT2JzeGI1SnlzTXIyS2dWcEdieDB4R1kxSEo2eXUydlRkVWlzOGdUTnVCQ2NwNjNjaFpCdVpxQkphZXYxLU9BaXhBWmdVYWVjQnY1N3Q1aUtqaER5LV9WVlNWZ3BXMk5WR0gwWnlIU3RIazJZelZJQUM1ek12ZDFodEg1eDFaRm56eTR5UEh3VQ?oc=5',\n",
    "  'content': 'DeepSeek Marks The End Of The First Phase Of The AI Investment Boom - Forbes'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再用 tool 装饰器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# Create a tool for searching news by keyword\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    print(query)\n",
    "    news_tool = GoogleNews()\n",
    "    return news_tool.search_by_keyword(query, k=5)\n",
    "\n",
    "\t\n",
    "# Execution Results\n",
    "search_keyword.invoke({\"query\": \"LangChain AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bind_tools\n",
    "\n",
    "`bind_tools` 是 LangChain 中的一个强大功能，用于将自定义工具与大语言模型 (LLMs) 集成，从而实现增强的 AI 工作流。\n",
    "\n",
    "接下来展示如何创建、绑定工具、解析并执行输出，并将它们集成到 `AgentExecutor` 中。\n",
    "\n",
    "![](https://python.langchain.com/assets/images/tool_calling_components-bef9d2bcb9d3706c2fe58b57bf8ccb60.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Define the tools\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Return the length of the given text\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_function(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together\"\"\"\n",
    "    return a + b\n",
    "\t\n",
    "\n",
    "tools = [get_word_length, add_function]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们使用 `bind_tools` 函数将定义的工具与特定的大语言模型 (LLM) 关联起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a model\n",
    "llm = ChatOpenAI(\n",
    "\tbase_url='http://localhost:5551/v1',\n",
    "\tapi_key='EMPTY',\n",
    "\tmodel_name='Qwen2.5-3B-Instruct',\n",
    "\ttemperature=0.2,\n",
    ")\n",
    "\n",
    "# Tool binding\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是绑定函数的说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(llm_with_tools.kwargs, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(\n",
    "    \"What is the length of the given text 'LangChain OpenTutorial'?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果存储在 `tool_calls` 中。让我们打印 `tool_calls`。\n",
    "\n",
    "[注意]\n",
    "\n",
    "- `name` 表示工具的名称。\n",
    "- `args` 包含传递给工具的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Execution result\n",
    "ret = llm_with_tools.invoke(\n",
    "    \"What is the length of the given text 'LangChain OpenTutorial'?\"\n",
    ")\n",
    "\n",
    "pprint(ret.__dict__)\n",
    "print(20*'-')\n",
    "pprint(ret.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tool 输出解析 JsonOutputToolsParser\n",
    "\n",
    "接下来，我们将把 `llm_with_tools` 与 `JsonOutputToolsParser` 连接起来，以解析 `tool_calls` 并查看结果。\n",
    "\n",
    "- `type` 表示工具的类型。\n",
    "- `args` 包含传递给工具的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "\n",
    "# Tool Binding + Tool Parser\n",
    "chain = llm_with_tools | JsonOutputToolsParser(tools=tools)\n",
    "\n",
    "# Execution Result\n",
    "tool_call_results = chain.invoke(\n",
    "    \"What is the length of the given text 'LangChain OpenTutorial'?\"\n",
    ")\n",
    "print(tool_call_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`execute_tool_calls` 函数识别合适的工具，传递相应的 `args`，然后执行该工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool_calls(tool_call_results):\n",
    "    \"\"\"\n",
    "    Function to execute the tool call results.\n",
    "\n",
    "    :param tool_call_results: List of the tool call results\n",
    "    :param tools: List of available tools\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over the list of the tool call results\n",
    "    for tool_call_result in tool_call_results:\n",
    "        # Tool name (function name)\n",
    "        tool_name = tool_call_result[\"type\"]\n",
    "        # Tool arguments\n",
    "        tool_args = tool_call_result[\"args\"]\n",
    "\n",
    "        # Find the tool that matches the name and execute it\n",
    "        # Use the next() function to find the first matching tool\n",
    "        matching_tool = next((tool for tool in tools if tool.name == tool_name), None)\n",
    "        if matching_tool:\n",
    "            # Execute the tool\n",
    "            result = matching_tool.invoke(tool_args)\n",
    "            print(\n",
    "                f\"[Executed Tool] {tool_name} [Args] {tool_args}\\n[Execution Result] {result}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Warning: Unable to find the tool corresponding to {tool_name}.\")\n",
    "\n",
    "\n",
    "# Execute the tool calls\n",
    "execute_tool_calls(tool_call_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将工具与解析器绑定以执行\n",
    "\n",
    "这次，我们将工具绑定、解析结果和执行工具调用的整个过程合并为一个步骤。\n",
    "\n",
    "- `llm_with_tools`：绑定工具的LLM模型。\n",
    "- `JsonOutputToolsParser`：处理工具调用结果的解析器。\n",
    "- `execute_tool_calls`：执行工具调用结果的函数。\n",
    "\n",
    "[流程摘要]\n",
    "\n",
    "1. 将工具绑定到模型。\n",
    "2. 解析工具调用的结果。\n",
    "3. 执行工具调用的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "\n",
    "# bind_tools + Parser + Execution\n",
    "chain = llm_with_tools | JsonOutputToolsParser(tools=tools) | execute_tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the length of the given text 'LangChain OpenTutorial'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Result 2\n",
    "chain.invoke(\"114.5 + 121.2\")\n",
    "\n",
    "# Double check\n",
    "print(114.5 + 121.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将工具与Agent和`AgentExecutor`绑定\n",
    "\n",
    "`bind_tools` 提供可以由模型使用的工具（schemas）。\n",
    "\n",
    "`AgentExecutor` 创建一个执行循环，用于执行诸如调用LLM、路由到合适的工具、执行工具以及重新调用模型等任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create an Agent prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a model\n",
    "llm = ChatOpenAI(\n",
    "\tbase_url='http://localhost:5551/v1',\n",
    "\tapi_key='EMPTY',\n",
    "\tmodel_name='Qwen2.5-3B-Instruct',\n",
    "\ttemperature=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "# Use the tools defined previously\n",
    "tools = [get_word_length, add_function]\n",
    "\n",
    "# Create an Agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create an AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Agent\n",
    "result = agent_executor.invoke(\n",
    "    {\"input\": \"What is the length of the given text 'LangChain OpenTutorial'?\"}\n",
    ")\n",
    "\n",
    "# Execution Result\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Agent\n",
    "result = agent_executor.invoke({\"input\": \"Calculate the result of 114.5 + 121.2\"})\n",
    "\n",
    "# Execution Result\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小模型的性能还是会存在解析和 reasoning 方面的错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling Agent\n",
    "\n",
    "在 LangChain 中，**工具调用**（tool calling）允许模型检测何时调用一个或多个**工具**，以及需要将什么输入传递给这些工具。\n",
    "\n",
    "在进行 API 调用时，你可以定义工具，并智能地引导模型生成结构化对象，例如 JSON，这些对象包含调用这些工具所需的参数。\n",
    "\n",
    "工具 API 的目标是提供比标准的文本生成或聊天 API 更加可靠的有效和有用的**工具调用**生成。\n",
    "\n",
    "你可以创建代理（agents），这些代理会迭代地调用工具并接收结果，直到通过整合这些结构化输出解决查询，并将多个工具绑定到一个工具调用的聊天模型，让模型选择调用哪些工具。\n",
    "\n",
    "这代表了一个更加**通用的版本**，它是为 OpenAI 的特定工具调用风格设计的 OpenAI 工具代理的扩展。\n",
    "\n",
    "这个代理使用 LangChain 的 `ToolCall` 接口，支持比 OpenAI 更广泛的提供者实现，包括 `Anthropic`、`Google Gemini` 和 `Mistral` 等。\n",
    "\n",
    "![](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/15-Agent/assets/15-agent-agent-concept.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建工具\n",
    "\n",
    "LangChain 允许你定义自定义工具，供你的代理与之交互。你可以创建用于搜索新闻或执行 Python 代码的工具。\n",
    "\n",
    "`@tool` 装饰器用于创建工具：\n",
    "- `TavilySearchResults` 是一个用于搜索新闻的工具。\n",
    "- `PythonREPL` 是一个用于执行 Python 代码的工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: search_news\n",
      "Tool description: Search news by input keyword using Tavily Search API\n",
      "Tool args: {'query': {'title': 'Query', 'type': 'string'}}\n",
      "--------------------\n",
      "Tool name: python_repl_tool\n",
      "Tool description: Use this tool to execute Python code. If you want to see the output of a value,\n",
      "    you should print it using print(...). This output is visible to the user.\n",
      "Tool args: {'code': {'description': 'The python code to execute to generate your chart.', 'title': 'Code', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import List, Dict, Annotated\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "\n",
    "# Creating tool for searching news\n",
    "@tool\n",
    "def search_news(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Search news by input keyword using Tavily Search API\"\"\"\n",
    "    news_tool = TavilySearchResults(\n",
    "        max_results=3,\n",
    "        include_answer=True,\n",
    "        include_raw_content=True,\n",
    "        include_images=True,\n",
    "        # search_depth=\"advanced\",\n",
    "        # include_domains = [],\n",
    "        # exclude_domains = []\n",
    "    )\n",
    "    return news_tool.invoke(query, k=3)\n",
    "\n",
    "\n",
    "# Creating tool for executing python code\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this tool to execute Python code. If you want to see the output of a value,\n",
    "    you should print it using print(...). This output is visible to the user.\"\"\"\n",
    "    result = \"\"\n",
    "    try:\n",
    "        result = PythonREPL().run(code)\n",
    "    except BaseException as e:\n",
    "        print(f\"Failed to execute. Error: {repr(e)}\")\n",
    "    finally:\n",
    "        return result\n",
    "\n",
    "\n",
    "print(f\"Tool name: {search_news.name}\")\n",
    "print(f\"Tool description: {search_news.description}\")\n",
    "print(f\"Tool args: {search_news.args}\")\n",
    "\n",
    "print('-'*20)\n",
    "print(f\"Tool name: {python_repl_tool.name}\")\n",
    "print(f\"Tool description: {python_repl_tool.description}\")\n",
    "print(f\"Tool args: {python_repl_tool.args}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/2024_in_the_United_States',\n",
       "  'content': \"In the Senate, at least six seats, those of Senators Tom Carper from Delaware, Mike Braun from Indiana, Ben Cardin from Maryland, Debbie Stabenow from Michigan, Mitt Romney from Utah, and Joe Manchin from West Virginia, will be open contests; the seat of the late Dianne Feinstein is also expected to be an open contest with Feinstein's immediate replacement, Laphonza Butler, expected to serve on an interim basis.[1][2][3]\\nConcerning state governments, 11 states and two territories will hold gubernatorial elections, and most states and territories will hold elections for their legislatures. Contents\\n2024 in the United States\\nThe following is a list of predicted and scheduled events of the year 2024 in the United States, that have not yet occurred.\\n With former president Donald Trump's declaration to run for the office again, the election may possibly be a rematch of the 2020 election, although the June 2023 indictment of Donald Trump may have a significant impact on Trump's presidential campaign. In the federal government, the offices of the president, vice president, all 435 seats of the House of Representatives, and roughly one third of the Senate. ←\\n→\\nElections[edit]\\nThe US general elections will be held on November 5 of this year.\"},\n",
       " {'url': 'https://abcnews.go.com/Entertainment/abc-news-year-2024-back-years-major-news/story?id=116448091',\n",
       "  'content': 'ABC News\\' \\'The Year: 2024\\' looks back at this year\\'s major news and entertainment events - ABC News ABC News ABC News\\' \\'The Year: 2024\\' looks back at this year\\'s major news and entertainment events As the world gears up for 2025, it leaves behind a year of war, political shifts, pop culture moments, sporting triumphs, lost stars and more. ABC News was there to chronicle every moment and will look back at this year\\'s defining events in a two-hour special, \"The Year: 2024,\" which airs Thursday, Dec. 26 at 9 p.m. ET, and streams afterwards on Hulu. The special also explores how the love lives of some of our favorite stars evolved this year. ABC News Live'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/2024',\n",
       "  'content': 'May 8 – In North Macedonian elections, the right-wing party VMRO-DPMNE wins in a landslide in the parliamentary elections, while its presidential candidate Gordana Siljanovska-Davkova is elected as the first female president of the country in the second round of the presidential election.[88][89] July 13 – While campaigning for the 2024 United States presidential election, former President Donald Trump is shot in the right ear in an assassination attempt at a rally he held near Butler, Pennsylvania.[139] July 28 – 2024 Venezuelan presidential election: Incumbent President Nicolás Maduro declares victory against opposition candidate Edmundo González Urrutia amid alleged irregularities, causing numerous South American states to refuse to acknowledge the results or suspend diplomatic relations with the Maduro government and sparking nationwide protests.[151]'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_news('2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tools\n",
    "tools = [search_news, python_repl_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建代理提示\n",
    "\n",
    "- `chat_history`：此变量存储对话历史记录，如果你的代理支持多轮对话，则使用此变量。（否则，可以省略此项。）\n",
    "- `agent_scratchpad`：此变量作为临时存储，用于存放中间变量。\n",
    "- `input`：此变量代表用户的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Creating prompt\n",
    "# Prompt is a text that describes the task the model should perform. (input the name and role of the tool)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"Make sure to use the `search_news` tool for searching keyword related news.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建代理\n",
    "\n",
    "使用 `create_tool_calling_agent` 函数定义一个代理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# Creating LLM\n",
    "llm = ChatOpenAI(\n",
    "\tbase_url='http://localhost:5551/v1',\n",
    "\tapi_key='EMPTY',\n",
    "\tmodel_name='Qwen2.5-3B-Instruct',\n",
    "\ttemperature=0.2,\n",
    ")\n",
    "\n",
    "# Creating Agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `AgentExecutor`\n",
    "\n",
    "`AgentExecutor` 是一个用于管理使用工具的代理的类。\n",
    "\n",
    "**关键属性**\n",
    "- `agent`：负责创建计划并在执行循环的每个步骤中确定行动的底层代理。\n",
    "- `tools`：包含代理被授权使用的所有有效工具的列表。\n",
    "- `return_intermediate_steps`：布尔标志，决定是否返回代理在执行过程中所采取的中间步骤以及最终输出。\n",
    "- `max_iterations`：代理在执行循环终止之前可以采取的最大步骤数。\n",
    "- `max_execution_time`：执行循环允许运行的最长时间。\n",
    "- `early_stopping_method`：定义当代理未返回 `AgentFinish` 时如何处理的方式。（\"force\" 或 \"generate\"）\n",
    "  - `\"force\"`：返回一个字符串，表示执行循环由于达到时间或迭代限制而被停止。\n",
    "  - `\"generate\"`：调用代理的 LLM 链一次，根据之前的步骤生成最终答案。\n",
    "- `handle_parsing_errors`：指定如何处理解析错误。（可以设置为 `True`、`False`，或提供自定义错误处理函数。）\n",
    "- `trim_intermediate_steps`：修剪中间步骤的方法。（可以设置为 `-1` 以保留所有步骤，或提供自定义修剪函数。）\n",
    "\n",
    "**关键方法**\n",
    "1. `invoke`：执行代理。\n",
    "2. `stream`：流式传输达到最终输出所需的步骤。\n",
    "\n",
    "**关键特性**\n",
    "1. **工具验证**：确保工具与代理兼容。\n",
    "2. **执行控制**：设置最大迭代次数和执行时间限制来管理代理行为。\n",
    "3. **错误处理**：提供多种处理输出解析错误的选项。\n",
    "4. **中间步骤管理**：允许修剪中间步骤或返回调试选项。\n",
    "5. **异步支持**：支持异步执行和结果的流式传输。\n",
    "\n",
    "**优化建议**\n",
    "- 设置适当的 `max_iterations` 和 `max_execution_time` 值来管理执行时间。\n",
    "- 使用 `trim_intermediate_steps` 来优化内存使用。\n",
    "- 对于复杂任务，使用 `stream` 方法来逐步监控结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_news` with `{'query': 'AI Agent 2025'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks', 'content': 'According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance. I expect to see more focus on multimodal AI models in education, including in processing speech and images. AI Agents Work Together In 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI agents of diverse expertise work together. As an example, we recently introduced the\\xa0Virtual Lab, where a professor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, open-ended research, with a human researcher providing high-level feedback. We will experience an emerging paradigm of research around how humans work together with AI agents.'}, {'url': 'https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/', 'content': 'AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents for the Enterprise will be the focus of 2025 To see what AI agents can do in 2025, let’s consider a simple example: an email-answering tool. Let’s improve our tool by building AI agents within a workflow. The Workflow of AI Agents: More Than Generative AI AI models can be connected or \"chained\" to build workflows where the output of one model becomes the input for the next. AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing 2025 - AI Agents for the Enterprise Follow me here on Forbes or on LinkedIn for more of my 2025 AI predictions.'}, {'url': 'https://www.godofprompt.ai/blog/ai-agents-you-cant-miss', 'content': 'Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.'}]\u001b[0m\u001b[32;1m\u001b[1;3mHere are some relevant news articles about AI Agents in 2025:\n",
      "\n",
      "1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\n",
      "\n",
      "2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on AI models being connected or \"chained\" to build workflows where the output of one model becomes the input for the next. It also mentions AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing.\n",
      "\n",
      "3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)\n",
      "\n",
      "These articles provide insights into the future of AI Agents, including their collaborative nature, their potential impact on enterprises, and the development of AI Agent Workflows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent execution result:\n",
      "Here are some relevant news articles about AI Agents in 2025:\n",
      "\n",
      "1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\n",
      "\n",
      "2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on AI models being connected or \"chained\" to build workflows where the output of one model becomes the input for the next. It also mentions AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing.\n",
      "\n",
      "3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)\n",
      "\n",
      "These articles provide insights into the future of AI Agents, including their collaborative nature, their potential impact on enterprises, and the development of AI Agent Workflows.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Create AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    max_iterations=10,\n",
    "    max_execution_time=10,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "# Run AgentExecutor\n",
    "result = agent_executor.invoke({\"input\": \"Search news about AI Agent in 2025.\"})\n",
    "\n",
    "print(\"Agent execution result:\")\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Stream 输出检查逐步结果\n",
    "\n",
    "我们将使用 `AgentExecutor` 的 `stream()` 方法来流式传输代理的中间步骤。\n",
    "\n",
    "`stream()` 的输出在 (Action, Observation) 对之间交替，最终如果目标达成，将以代理的答案结束。\n",
    "\n",
    "流程如下所示：\n",
    "\n",
    "1. Action 输出\n",
    "2. Observation 输出\n",
    "3. Action 输出\n",
    "4. Observation 输出\n",
    "\n",
    "...（继续直到目标达成）...\n",
    "\n",
    "然后，代理将在目标达成后得出最终答案。\n",
    "\n",
    "以下表格总结了你将在输出中遇到的内容：\n",
    "\n",
    "| 输出 | 描述 |\n",
    "|------|------|\n",
    "| Action | `actions`：表示 `AgentAction` 或其子类。<br>`messages`：与动作调用对应的聊天消息。 |\n",
    "| Observation | `steps`：记录代理的工作，包括当前的动作和其观察结果。<br>`messages`：包含函数调用结果（即观察结果）的聊天消息。 |\n",
    "| Final Answer | `output`：表示 `AgentFinish` 信号。<br>`messages`：包含最终输出的聊天消息。 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actions': [ToolAgentAction(tool='search_news', tool_input={'query': 'AI Agent 2025'}, log=\"\\nInvoking: `search_news` with `{'query': 'AI Agent 2025'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'function': {'arguments': '{\"query\": \"AI Agent 2025\"}', 'name': 'search_news'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen2.5-3B-Instruct'}, id='run-a877dfea-5a20-4970-96da-0f3483298f7e', tool_calls=[{'name': 'search_news', 'args': {'query': 'AI Agent 2025'}, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'search_news', 'args': '{\"query\": \"AI Agent 2025\"}', 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='chatcmpl-tool-cf8525019f5847519566061e0e6647c6')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'function': {'arguments': '{\"query\": \"AI Agent 2025\"}', 'name': 'search_news'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen2.5-3B-Instruct'}, id='run-a877dfea-5a20-4970-96da-0f3483298f7e', tool_calls=[{'name': 'search_news', 'args': {'query': 'AI Agent 2025'}, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'search_news', 'args': '{\"query\": \"AI Agent 2025\"}', 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'index': 0, 'type': 'tool_call_chunk'}])]}\n",
      "============================================================\n",
      "{'steps': [AgentStep(action=ToolAgentAction(tool='search_news', tool_input={'query': 'AI Agent 2025'}, log=\"\\nInvoking: `search_news` with `{'query': 'AI Agent 2025'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'function': {'arguments': '{\"query\": \"AI Agent 2025\"}', 'name': 'search_news'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen2.5-3B-Instruct'}, id='run-a877dfea-5a20-4970-96da-0f3483298f7e', tool_calls=[{'name': 'search_news', 'args': {'query': 'AI Agent 2025'}, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'search_news', 'args': '{\"query\": \"AI Agent 2025\"}', 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='chatcmpl-tool-cf8525019f5847519566061e0e6647c6'), observation=[{'url': 'https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks', 'content': 'According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance. I expect to see more focus on multimodal AI models in education, including in processing speech and images. AI Agents Work Together In 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI agents of diverse expertise work together. As an example, we recently introduced the\\xa0Virtual Lab, where a professor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, open-ended research, with a human researcher providing high-level feedback. We will experience an emerging paradigm of research around how humans work together with AI agents.'}, {'url': 'https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/', 'content': 'AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents for the Enterprise will be the focus of 2025 To see what AI agents can do in 2025, let’s consider a simple example: an email-answering tool. Let’s improve our tool by building AI agents within a workflow. The Workflow of AI Agents: More Than Generative AI AI models can be connected or \"chained\" to build workflows where the output of one model becomes the input for the next. AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing 2025 - AI Agents for the Enterprise Follow me here on Forbes or on LinkedIn for more of my 2025 AI predictions.'}, {'url': 'https://www.godofprompt.ai/blog/ai-agents-you-cant-miss', 'content': 'Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.'}])], 'messages': [FunctionMessage(content='[{\"url\": \"https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks\", \"content\": \"According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance. I expect to see more focus on multimodal AI models in education, including in processing speech and images. AI Agents Work Together In 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI agents of diverse expertise work together. As an example, we recently introduced the\\xa0Virtual Lab, where a professor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, open-ended research, with a human researcher providing high-level feedback. We will experience an emerging paradigm of research around how humans work together with AI agents.\"}, {\"url\": \"https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/\", \"content\": \"AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents for the Enterprise will be the focus of 2025 To see what AI agents can do in 2025, let’s consider a simple example: an email-answering tool. Let’s improve our tool by building AI agents within a workflow. The Workflow of AI Agents: More Than Generative AI AI models can be connected or \\\\\"chained\\\\\" to build workflows where the output of one model becomes the input for the next. AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing 2025 - AI Agents for the Enterprise Follow me here on Forbes or on LinkedIn for more of my 2025 AI predictions.\"}, {\"url\": \"https://www.godofprompt.ai/blog/ai-agents-you-cant-miss\", \"content\": \"Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.\"}]', additional_kwargs={}, response_metadata={}, name='search_news')]}\n",
      "============================================================\n",
      "{'output': 'Here are some relevant news articles about AI Agents in 2025:\\n\\n1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\\n\\n2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on how AI models can be connected or \"chained\" to build workflows where the output of one model becomes the input for the next.\\n\\n3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)\\n\\nThese articles provide insights into the expected trends and developments in AI Agents for both research and enterprise applications in the year 2025.', 'messages': [AIMessage(content='Here are some relevant news articles about AI Agents in 2025:\\n\\n1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\\n\\n2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on how AI models can be connected or \"chained\" to build workflows where the output of one model becomes the input for the next.\\n\\n3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)\\n\\nThese articles provide insights into the expected trends and developments in AI Agents for both research and enterprise applications in the year 2025.', additional_kwargs={}, response_metadata={})]}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Create AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "# Run in streaming mode\n",
    "result = agent_executor.stream({\"input\": \"Search news about AI Agent in 2025.\"})\n",
    "\n",
    "for step in result:\n",
    "    # Print intermediate steps\n",
    "    print(step)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用用户定义的函数自定义中间步骤输出\n",
    "\n",
    "你可以定义以下 3 个函数来自定义中间步骤的输出：\n",
    "\n",
    "- `tool_callback`：此函数处理工具调用生成的输出。\n",
    "- `observation_callback`：此函数处理观察数据输出。\n",
    "- `result_callback`：此函数允许你处理最终答案的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "# Create AgentStreamParser class\n",
    "class AgentStreamParser:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def tool_callback(self, tool: Dict[str, Any]) -> None:\n",
    "        print(\"\\n=== Tool Called ===\")\n",
    "        print(f\"Tool: {tool.get('tool')}\")\n",
    "        print(f\"Input: {tool.get('tool_input')}\")\n",
    "        print(\"==================\\n\")\n",
    "\n",
    "    def observation_callback(self, step: Dict[str, Any]) -> None:\n",
    "        print(\"\\n=== Observation ===\")\n",
    "        observation_data = step[\"steps\"][0].observation\n",
    "        print(f\"Observation: {observation_data}\")\n",
    "        print(\"===================\\n\")\n",
    "\n",
    "    def result_callback(self, result: str) -> None:\n",
    "        print(\"\\n=== Final Answer ===\")\n",
    "        print(result)\n",
    "        print(\"====================\\n\")\n",
    "\n",
    "    def process_agent_steps(self, step: Dict[str, Any]) -> None:\n",
    "        if \"actions\" in step:\n",
    "            for action in step[\"actions\"]:\n",
    "                self.tool_callback(\n",
    "                    {\"tool\": action.tool, \"tool_input\": action.tool_input}\n",
    "                )\n",
    "        elif \"output\" in step:\n",
    "            self.result_callback(step[\"output\"])\n",
    "        else:\n",
    "            self.observation_callback(step)\n",
    "\n",
    "\n",
    "# Create AgentStreamParser instance\n",
    "agent_stream_parser = AgentStreamParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tool Called ===\n",
      "Tool: numpy_array_generator\n",
      "Input: {'start': 1, 'step': 0.1}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: numpy_array_generator is not a valid tool, try one of [search_news, python_repl_tool].\n",
      "===================\n",
      "\n",
      "\n",
      "=== Tool Called ===\n",
      "Tool: python_repl_tool\n",
      "Input: {'code': 'import numpy as np\\nnp.arange(0, 1, 0.1)'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: \n",
      "===================\n",
      "\n",
      "\n",
      "=== Tool Called ===\n",
      "Tool: python_repl_tool\n",
      "Input: {'code': 'import numpy as np\\nnp.arange(0, 1, 0.1)'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: \n",
      "===================\n",
      "\n",
      "\n",
      "=== Tool Called ===\n",
      "Tool: python_repl_tool\n",
      "Input: {'code': 'import numpy as np\\nnp.arange(0, 1, 0.1)'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: \n",
      "===================\n",
      "\n",
      "\n",
      "=== Final Answer ===\n",
      "The numpy array from 0 to 1 with a stride of 0.1 has been successfully generated. Here it is:\n",
      "\n",
      "```\n",
      "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
      "```\n",
      "\n",
      "Is there anything else I can assist you with?\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run in streaming mode\n",
    "result = agent_executor.stream({\"input\": \"Generate a array from 0 to 1 with the stride of 0.1 using numpy.\"})\n",
    "# result = agent_executor.stream({\"input\": \"Search news about AI Agent in 2025.\"})\n",
    "\n",
    "\n",
    "for step in result:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与之前的对话历史进行代理通信\n",
    "\n",
    "为了记住过去的对话，你可以将 `AgentExecutor` 包装在 `RunnableWithMessageHistory` 中。\n",
    "\n",
    "有关 `RunnableWithMessageHistory` 的更多细节，请参阅以下链接。\n",
    "\n",
    "**参考**\n",
    "- [LangChain Python API Reference > langchain: 0.3.14 > core > runnables > langchain_core.runnables.history > RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Create a dictionary to store session_id\n",
    "store = {}\n",
    "\n",
    "\n",
    "# Function to get session history based on session_id\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in store:  # If session_id is not in store\n",
    "        # Create a new ChatMessageHistory object and store it in store\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # Return session history for the corresponding session_id\n",
    "\n",
    "\n",
    "# Create an agent with chat message history\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # Chat session_id\n",
    "    get_session_history,\n",
    "    # The key for the question input in the prompt: \"input\"\n",
    "    input_messages_key=\"input\",\n",
    "    # The key for the message input in the prompt: \"chat_history\"\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Answer ===\n",
      "Hello Teddy! It's nice to meet you. How can I assist you today? Do you have any specific questions or topics you'd like to explore?\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Request streaming output for the query\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"Hello! My name is Teddy!\"},\n",
    "    # Set session_id\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "# Check the output\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Answer ===\n",
      "It seems like you've already provided your name as Teddy. If you have any other questions or need information about something else, feel free to ask!\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Request streaming output for the query\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    # Set session_id\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "# Check the output\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tool Called ===\n",
      "Tool: search_news\n",
      "Input: {'query': 'TeddyNote Co., Ltd.'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: [{'url': 'https://www.youtube.com/@teddynote', 'content': '데이터 분석, 머신러닝, 딥러닝, LLM 에 대한 내용을 다룹니다. 연구보다는 개발에 관심이 많습니다 🙇\\u200d♂️🔥 \"테디노트의 RAG 비법노트\" 랭체인'}, {'url': 'https://github.com/teddynote', 'content': 'By company size. Enterprises Small and medium teams Startups Nonprofits By use case. DevSecOps DevOps CI/CD View all use cases By industry ... teddynote.github.io teddynote.github.io Public. Forked from mmistakes/minimal-mistakes. 📐 Jekyll theme for building a personal site, blog, project documentation, or portfolio.'}, {'url': 'https://github.com/teddylee777', 'content': 'Jupyter Notebook\\n1\\n4\\nConv2d and MaxPool2d Calculator for PyTorch\\nPython\\n18\\n1\\nStreamlit 튜토리얼 😁\\nJupyter Notebook\\n13\\n12\\n주가 종목 패턴 발굴기\\nJupyter Notebook\\n14\\n12\\n586\\ncontributions\\nin the last year\\nContribution activity\\nJanuary 2024\\nSeeing something unexpected? Teddy Lee\\nteddylee777\\nAchievements\\nAchievements\\nHighlights\\nBlock or report teddylee777\\nPrevent this user from interacting with your repositories and sending you notifications.\\n Jupyter Notebook\\n58\\n16\\nForked from lovedlim/tensorflow\\n텐서플로 도서 예제 파일입니다.\\n Samsung Electronics\\n테디노트 Blog\\n테디노트 YouTube\\n@teddynote\\nLinkedIn\\n💻 (This repository is intented for helping whom are interested in machine learning study)\\nJupyter Notebook\\n2.3k\\n789\\n머신러닝/딥러닝(PyTorch, TensorFlow) 전용 도커입니다.'}]\n",
      "===================\n",
      "\n",
      "\n",
      "=== Final Answer ===\n",
      "Here are some recent news and information related to your company, TeddyNote Co., Ltd.:\n",
      "\n",
      "1. **TeddyNote Co., Ltd. on YouTube**: They have a YouTube channel where they discuss topics related to data analysis, machine learning, deep learning, and Large Language Models (LLM). They seem to have a focus on development rather than research. You can check out their channel [here](https://www.youtube.com/@teddynote).\n",
      "\n",
      "2. **TeddyNote Co., Ltd. on GitHub**: \n",
      "   - **Company Size**: They cater to small and medium-sized teams, startups, and nonprofits.\n",
      "   - **Use Cases**: They support DevSecOps and DevOps, CI/CD.\n",
      "   - **Public Repository**: You can view their public repository [here](https://github.com/teddynote).\n",
      "   - **Personal Site**: They have a personal site and blog available at [teddynote.github.io](https://teddynote.github.io/).\n",
      "   - **Contributions**: They have contributed to various projects, including a Jupyter Notebook for a Conv2d and MaxPool2d Calculator for PyTorch, a Streamlit tutorial, and a stock price pattern analysis tool. You can see their contributions [here](https://github.com/teddylee777).\n",
      "\n",
      "3. **TeddyLee777 on GitHub**: This is likely a personal GitHub account associated with TeddyNote Co., Ltd. They have contributed to various projects, including a TensorFlow book example repository and a Docker image for machine learning study.\n",
      "\n",
      "If you need more detailed information or have any specific questions about these resources, feel free to ask!\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Request streaming output for the query\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"My email address is teddy@teddynote.com. The company name is TeddyNote Co., Ltd.\"\n",
    "    },\n",
    "    # Set session_id\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "# Check the output\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tool Called ===\n",
      "Tool: search_news\n",
      "Input: {'query': 'TeddyNote Co., Ltd latest news'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Tool Called ===\n",
      "Tool: python_repl_tool\n",
      "Input: {'code': 'import email; from email.mime.multipart import MIMEMultipart; from email.mime.text import MIMEText; msg = MIMEMultipart(); msg[\\'From\\'] = \\'teddy@teddynote.com\\'; msg[\\'To\\'] = \\'sally@example.com\\'; msg[\\'Subject\\'] = \\'Latest News from TeddyNote Co., Ltd\\'; body = \"\"\"Here are the latest news and updates from TeddyNote Co., Ltd.:\\n\\n1. **TeddyNote Co., Ltd. on YouTube**: They have a YouTube channel where they discuss topics related to data analysis, machine learning, deep learning, and Large Language Models (LLM). They seem to have a focus on development rather than research. You can check out their channel [here](https://www.youtube.com/@teddynote).\\n\\n2. **TeddyNote Co., Ltd. on GitHub**: \\n   - **Company Size**: They cater to small and medium-sized teams, startups, and nonprofits.\\n   - **Use Cases**: They support DevSecOps and DevOps, CI/CD.\\n   - **Public Repository**: You can view their public repository [here](https://github.com/teddynote).\\n   - **Personal Site**: They have a personal site and blog available at [teddynote.github.io](https://teddynote.github.io/).\\n   - **Contributions**: They have contributed to various projects, including a Jupyter Notebook for a Conv2d and MaxPool2d Calculator for PyTorch, a Streamlit tutorial, and a stock price pattern analysis tool. You can see their contributions [here](https://github.com/teddylee777).\\n\\n3. **TeddyLee777 on GitHub**: This is likely a personal GitHub account associated with TeddyNote Co., Ltd. They have contributed to various projects, including a TensorFlow book example repository and a Docker image for machine learning study.\\n\\nIf you need more detailed information or have any specific questions about these resources, feel free to ask!\"\"\"; msg.attach(MIMEText(body, \\'plain\\')); return msg.as_string()'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Tool Called ===\n",
      "Tool: send_email\n",
      "Input: {'to': 'sally@example.com', 'subject': 'Latest News from TeddyNote Co., Ltd', 'body': '...', 'sender': 'teddy@teddynote.com'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Tool Called ===\n",
      "Tool: email_status\n",
      "Input: {'email_id': '...'}\n",
      "==================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: [{'url': 'https://www.threads.net/@teddynote', 'content': '60 Followers • 44 Threads • 데이터 & AI. See the latest conversations with @teddynote.'}, {'url': 'https://github.com/teddylee777', 'content': 'Jupyter Notebook\\n1\\n4\\nConv2d and MaxPool2d Calculator for PyTorch\\nPython\\n18\\n1\\nStreamlit 튜토리얼 😁\\nJupyter Notebook\\n13\\n12\\n주가 종목 패턴 발굴기\\nJupyter Notebook\\n14\\n12\\n586\\ncontributions\\nin the last year\\nContribution activity\\nJanuary 2024\\nSeeing something unexpected? Teddy Lee\\nteddylee777\\nAchievements\\nAchievements\\nHighlights\\nBlock or report teddylee777\\nPrevent this user from interacting with your repositories and sending you notifications.\\n Jupyter Notebook\\n58\\n16\\nForked from lovedlim/tensorflow\\n텐서플로 도서 예제 파일입니다.\\n Samsung Electronics\\n테디노트 Blog\\n테디노트 YouTube\\n@teddynote\\nLinkedIn\\n💻 (This repository is intented for helping whom are interested in machine learning study)\\nJupyter Notebook\\n2.3k\\n789\\n머신러닝/딥러닝(PyTorch, TensorFlow) 전용 도커입니다.'}, {'url': 'https://langchain-opentutorial.gitbook.io/langchain-opentutorial/15-agent/03-agent', 'content': 'Best regards, Teddy teddy@teddynote.com TeddyNote Co., Ltd. --- Feel free to modify any part of the email as you see fit! >>>>>'}]\n",
      "===================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: SyntaxError(\"'return' outside function\", ('<string>', 14, 152, None, 14, 174))\n",
      "===================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: send_email is not a valid tool, try one of [search_news, python_repl_tool].\n",
      "===================\n",
      "\n",
      "\n",
      "=== Observation ===\n",
      "Observation: email_status is not a valid tool, try one of [search_news, python_repl_tool].\n",
      "===================\n",
      "\n",
      "\n",
      "=== Final Answer ===\n",
      "It seems there was an issue with the previous steps. Let's proceed with creating the email body using the news and information we gathered. Here is the body of the email:\n",
      "\n",
      "---\n",
      "\n",
      "Hello Ms. Sally,\n",
      "\n",
      "I hope this email finds you well. I wanted to share some recent news and updates from TeddyNote Co., Ltd.:\n",
      "\n",
      "1. **TeddyNote Co., Ltd. on YouTube**: They have a YouTube channel where they discuss topics related to data analysis, machine learning, deep learning, and Large Language Models (LLM). They seem to have a focus on development rather than research. You can check out their channel [here](https://www.youtube.com/@teddynote).\n",
      "\n",
      "2. **TeddyNote Co., Ltd. on GitHub**:\n",
      "   - **Company Size**: They cater to small and medium-sized teams, startups, and nonprofits.\n",
      "   - **Use Cases**: They support DevSecOps and DevOps, CI/CD.\n",
      "   - **Public Repository**: You can view their public repository [here](https://github.com/teddynote).\n",
      "   - **Personal Site**: They have a personal site and blog available at [teddynote.github.io](https://teddynote.github.io/).\n",
      "   - **Contributions**: They have contributed to various projects, including a Jupyter Notebook for a Conv2d and MaxPool2d Calculator for PyTorch, a Streamlit tutorial, and a stock price pattern analysis tool. You can see their contributions [here](https://github.com/teddylee777).\n",
      "\n",
      "3. **TeddyLee777 on GitHub**: This is likely a personal GitHub account associated with TeddyNote Co., Ltd. They have contributed to various projects, including a TensorFlow book example repository and a Docker image for machine learning study.\n",
      "\n",
      "If you need more detailed information or have any specific questions about these resources, feel free to ask!\n",
      "\n",
      "Best regards,\n",
      "Teddy\n",
      "teddy@teddynote.com\n",
      "TeddyNote Co., Ltd.\n",
      "\n",
      "---\n",
      "\n",
      "Please let me know if you need any further assistance or if there are any specific details you would like to include.\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Request streaming output for the query\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"Search the latest news and write it as the body of the email. \"\n",
    "        \"The recipient is `Ms. Sally` and the sender is my personal information.\"\n",
    "        \"Write in a polite tone, and include appropriate greetings and closings at the beginning and end of the email.\"\n",
    "    },\n",
    "    # Set session_id\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "# Check the output\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG\n",
    "\n",
    "**Agentic RAG** 扩展了传统的 RAG（检索增强生成）系统，通过结合基于代理的方法，实现更复杂的信息检索和响应生成。该系统不仅仅局限于简单的文档检索和响应生成，还允许代理利用各种工具进行更智能的信息处理。这些工具包括用于访问最新信息的 `Tavily Search`、执行 Python 代码的能力以及自定义功能实现，所有这些都集成在 `LangChain` 框架中，为信息处理和生成任务提供全面的解决方案。\n",
    "\n",
    "本教程演示了如何构建一个文档检索系统，使用 `FAISS DB` 来有效地处理和搜索 PDF 文档。以软件政策研究所的 AI Brief 为示例文档，我们将探索如何将基于 Web 的文档加载器、文本拆分器、向量存储和 `OpenAI` 嵌入结合起来，创建一个实际的 **Agentic RAG** 系统。该实现展示了如何将 `Retriever` 工具与各种 `LangChain` 组件有效结合，创建一个强大的文档搜索和响应生成管道。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Create a search tool instance that returns up to 6 results\n",
    "search = TavilySearchResults(k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# Load and process the PDF\n",
    "loader = PyPDFLoader(\"data/What-is-AI.pdf\")\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "\n",
    "# Split the document\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Create vector store\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v2\",\n",
    ")\n",
    "vector = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Create retriever\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# Create retriever tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"pdf_search\",\n",
    "    description=\"use this tool to search information from the PDF document\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "\tbase_url='http://localhost:5551/v1',\n",
    "\tapi_key='EMPTY',\n",
    "\tmodel_name='Qwen2.5-3B-Instruct',\n",
    "\ttemperature=0.2,\n",
    ")\n",
    "\n",
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"Make sure to use the `pdf_search` tool for searching information from the PDF document. \"\n",
    "            \"If you can't find the information from the PDF document, use the `search` tool for searching information from the web.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Create a store for session histories\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in store:\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]\n",
    "\n",
    "\n",
    "# Create agent with chat history\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(response):\n",
    "    \"\"\"\n",
    "    Process and display streaming response from the agent.\n",
    "\n",
    "    Args:\n",
    "        response: Agent's streaming response iterator\n",
    "    \"\"\"\n",
    "    for chunk in response:\n",
    "        if chunk.get(\"output\"):\n",
    "            print(chunk[\"output\"])\n",
    "        elif chunk.get(\"actions\"):\n",
    "            for action in chunk[\"actions\"]:\n",
    "                print(f\"\\nTool Used: {action.tool}\")\n",
    "                print(f\"Tool Input: {action.tool_input}\")\n",
    "                if action.log:\n",
    "                    print(f\"Tool Log: {action.log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool Used: pdf_search\n",
      "Tool Input: {'query': 'Samsung AI model'}\n",
      "Tool Log: \n",
      "Invoking: `pdf_search` with `{'query': 'Samsung AI model'}`\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tool Used: search\n",
      "Tool Input: {'query': 'Samsung AI model'}\n",
      "Tool Log: \n",
      "Invoking: `search` with `{'query': 'Samsung AI model'}`\n",
      "responded: The provided text does not contain specific information about Samsung's AI model. It seems to be a general introduction to AI, its components, and some real-world applications. To find information about Samsung's AI model, we might need to look for more detailed or specific documents or articles. Let me try searching the web for more relevant information.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tool Used: tavily_search_results_json\n",
      "Tool Input: {'query': 'Samsung AI model'}\n",
      "Tool Log: \n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Samsung AI model'}`\n",
      "responded: It appears that the 'search' tool is not available. Let's try using the 'tavily_search_results_json' tool to search the web for information about Samsung's AI model.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The search results provide information about Samsung's AI model, specifically Samsung Gauss 2, which is described as a new GenAI model that improves Galaxy AI performance and efficiency. Here are some key points from the search results:\n",
      "\n",
      "1. **Samsung Gauss 2**: This model supports 9 to 14 human languages and several programming languages. Samsung claims that Balanced and Supreme models match or beat other AI models on tasks.\n",
      "\n",
      "2. **Galaxy S25 Series**: The Galaxy S25 series features advanced, efficient AI image processing with ProScaler11, achieving a 40% improvement in display image scaling quality. It also incorporates custom technology with Samsung’s mobile Digital Natural Image engine (mDNIe) embedded within the processor using Galaxy IP to enable greater display power efficiency.\n",
      "\n",
      "3. **Galaxy AI**: Samsung's Galaxy AI is described as a set of generative AI tools that brings features like live translation, generative photo editing, and more. The AI features are available on newer Samsung phones, but Samsung is making efforts to support these features on older models as well.\n",
      "\n",
      "4. **Samsung Gauss 2 on Device**: Samsung Gauss 2 is an on-device AI model, which means it processes data locally on the device rather than sending it to a cloud server.\n",
      "\n",
      "These results suggest that Samsung Gauss 2 is a significant advancement in their AI capabilities, particularly in improving Galaxy AI performance and efficiency. If you need more detailed information, you might want to look into the specific features and capabilities of Samsung Gauss 2 in more detail.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Searching in PDF\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"What information can you find about Samsung's AI model in the document?\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"tutorial_session_1\"}},\n",
    ")\n",
    "process_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool Used: pdf_search\n",
      "Tool Input: {'query': 'devices using ai'}\n",
      "Tool Log: \n",
      "Invoking: `pdf_search` with `{'query': 'devices using ai'}`\n",
      "\n",
      "\n",
      "\n",
      "Based on the information provided in the document, the devices mentioned that use AI are:\n",
      "\n",
      "1. **Smartphones**: The document mentions that AI is available on newer Samsung phones, indicating that smartphones are one of the devices using AI.\n",
      "2. **Galaxy S25 Series**: The document describes the Galaxy S25 series as featuring advanced, efficient AI image processing, which implies that this device uses AI.\n",
      "3. **Galaxy AI**: The document states that Galaxy AI is a set of generative AI tools available on newer Samsung phones, suggesting that the Galaxy S25 series and possibly other newer Samsung devices use AI.\n",
      "4. **Smart City Initiative**: The document provides an example of a government initiative using AI for real-time video analytics, advanced forensic investigation capabilities, and comprehensive operational intelligence. While it doesn't specify which devices are used, it implies that AI is used across various devices in this context.\n",
      "\n",
      "Therefore, the devices using AI mentioned in the document are:\n",
      "- Smartphones (Samsung)\n",
      "- Galaxy S25 Series\n",
      "- Galaxy AI (presumably available on newer Samsung phones)\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Searching in PDF\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"List the devices using ai in your previous responese.\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"tutorial_session_1\"}},\n",
    ")\n",
    "process_response(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xprepo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
