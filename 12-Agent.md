# Tool

å·¥å…·æ˜¯ä¸€ä¸ªæ¥å£ï¼Œå…è®¸ä»£ç†ã€é“¾æ¡æˆ–å¤§è¯­è¨€æ¨¡å‹ä¸å¤–éƒ¨ä¸–ç•Œäº’åŠ¨ã€‚

LangChain æä¾›äº†æ˜“äºä½¿ç”¨çš„å†…ç½®å·¥å…·ï¼Œå¹¶ä¸”è¿˜å…è®¸ç”¨æˆ·è½»æ¾æ„å»ºè‡ªå®šä¹‰å·¥å…·ã€‚

**ä½ å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥ä¸­æ‰¾åˆ°é›†æˆåˆ° LangChain ä¸­çš„å·¥å…·åˆ—è¡¨ã€‚**

- [é›†æˆåˆ° LangChain ä¸­çš„å·¥å…·åˆ—è¡¨](https://python.langchain.com/docs/integrations/tools/)

## å†…ç½®å·¥å…· Built-in tools

ä½ å¯ä»¥ä½¿ç”¨ LangChain æä¾›çš„é¢„å®šä¹‰å·¥å…·å’Œå·¥å…·åŒ…ã€‚

å·¥å…·æŒ‡çš„æ˜¯å•ä¸€çš„å®ç”¨å·¥å…·ï¼Œè€Œå·¥å…·åŒ…å°†å¤šä¸ªå·¥å…·ç»„åˆæˆä¸€ä¸ªå•å…ƒä¾›ä½¿ç”¨ã€‚

ä½ å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥ä¸­æ‰¾åˆ°ç›¸å…³çš„å·¥å…·ã€‚

**æ³¨æ„**
- [LangChain å·¥å…·/å·¥å…·åŒ…](https://python.langchain.com/docs/integrations/tools/)

web æ£€ç´¢å·¥å…·


```python
from langchain_community.utilities import GoogleSerperAPIWrapper

search = GoogleSerperAPIWrapper()
search.run("Obama's first name?")
```

å›¾ç‰‡ç”Ÿæˆå·¥å…·


```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# Initialize the ChatOpenAI model
llm = ChatOpenAI(
	base_url='http://localhost:5551/v1',
	api_key='EMPTY',
	model_name='Qwen2.5-7B-Instruct',
	temperature=0.2,
)

# Define a prompt template for DALL-E image generation
prompt = PromptTemplate.from_template(
    "Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. "
    "Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt"
    "Output should be less than 1000 characters. Write in English only."
    "Image Description: \n{image_desc}",
)

# Create a chain connecting the prompt, LLM, and output parser
chain = prompt | llm | StrOutputParser()

# Execute the chain
image_prompt = chain.invoke(
    {"image_desc": "A Neo-Classicism painting satirizing people looking at their smartphones."}
)

# Output the image prompt
print(image_prompt)
```

å‡ ä¹æ‰€æœ‰ tool éƒ½æ˜¯éœ€è¦ api key çš„

## Python REPL å·¥å…·

æ­¤å·¥å…·æä¾›ä¸€ä¸ªç±»ï¼Œç”¨äºåœ¨ **REPL (Read-Eval-Print Loop)** ç¯å¢ƒä¸­æ‰§è¡Œ Python ä»£ç ã€‚
- [PythonREPLTool](https://python.langchain.com/docs/integrations/tools/python/)

**æè¿°**

- æä¾›ä¸€ä¸ª Python shell ç¯å¢ƒã€‚
- æ‰§è¡Œæœ‰æ•ˆçš„ Python å‘½ä»¤ä½œä¸ºè¾“å…¥ã€‚
- ä½¿ç”¨ `print(...)` å‡½æ•°æŸ¥çœ‹ç»“æœã€‚

**ä¸»è¦ç‰¹ç‚¹**

- sanitize_inputï¼šå¯é€‰é¡¹ï¼Œç”¨äºæ¸…ç†è¾“å…¥ï¼ˆé»˜è®¤ï¼šTrueï¼‰
- python_replï¼š**PythonREPL** çš„å®ä¾‹ï¼ˆé»˜è®¤ï¼šåœ¨å…¨å±€ä½œç”¨åŸŸä¸­æ‰§è¡Œï¼‰

**ä½¿ç”¨æ–¹æ³•**

- åˆ›å»º `PythonREPLTool` çš„å®ä¾‹ã€‚
- ä½¿ç”¨ `run`ã€`arun` æˆ– `invoke` æ–¹æ³•æ‰§è¡Œ Python ä»£ç ã€‚

**è¾“å…¥æ¸…ç†**

- ä»è¾“å…¥å­—ç¬¦ä¸²ä¸­ç§»é™¤ä¸å¿…è¦çš„ç©ºæ ¼ã€åå¼•å·ã€å…³é”®å­— "python" å’Œå…¶ä»–å¤šä½™çš„å…ƒç´ ã€‚


```python
from langchain_experimental.tools import PythonREPLTool

# Creates a tool for executing Python code.
python_tool = PythonREPLTool()

# Executes Python code and returns the results.
print(python_tool.invoke("print(100 + 200)"))
```

ä¸‹é¢æ˜¯è¯·æ±‚å¤§è¯­è¨€æ¨¡å‹ç¼–å†™ Python ä»£ç å¹¶è¿”å›ç»“æœçš„ç¤ºä¾‹ã€‚

**å·¥ä½œæµç¨‹æ¦‚è¿°**
1. è¯·æ±‚å¤§è¯­è¨€æ¨¡å‹ä¸ºç‰¹å®šä»»åŠ¡ç¼–å†™ Python ä»£ç ã€‚
2. æ‰§è¡Œç”Ÿæˆçš„ä»£ç ä»¥è·å–ç»“æœã€‚
3. è¾“å‡ºç»“æœã€‚



```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

python_tool = PythonREPLTool()
# A function that executes Python code, outputs intermediate steps, and returns the tool execution results.
def print_and_execute(code, debug=True):
    if debug:
        print("CODE:")
        print(code)
    return python_tool.invoke(code)


# A prompt requesting Python code to be written.
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. "
            "Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.",
        ),
        ("human", "{input}"),
    ]
)
# Create LLM model.
llm = ChatOpenAI(
	base_url='http://localhost:5551/v1',
	api_key='EMPTY',
	model_name='Qwen2.5-7B-Instruct',
	temperature=0.2,
)

# Create a chain using the prompt and the LLM model.
chain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)

# Outputting the results.
print(chain.invoke("Write code to generate Powerball numbers."))
```

## è‡ªå®šä¹‰å·¥å…·

é™¤äº† LangChain æä¾›çš„å†…ç½®å·¥å…·å¤–ï¼Œä½ è¿˜å¯ä»¥å®šä¹‰å’Œä½¿ç”¨è‡ªå·±çš„è‡ªå®šä¹‰å·¥å…·ã€‚

ä¸ºæ­¤ï¼Œå¯ä»¥ä½¿ç”¨ `langchain.tools` æ¨¡å—æä¾›çš„ `@tool` è£…é¥°å™¨å°†ä¸€ä¸ªå‡½æ•°è½¬æ¢ä¸ºå·¥å…·ã€‚

@tool è£…é¥°å™¨: è¿™ä¸ªè£…é¥°å™¨å…è®¸ä½ å°†ä¸€ä¸ªå‡½æ•°è½¬æ¢ä¸ºå·¥å…·ã€‚å®ƒæä¾›äº†å„ç§é€‰é¡¹æ¥å®šåˆ¶å·¥å…·çš„è¡Œä¸ºã€‚

**ä½¿ç”¨æ–¹æ³•**
1. åœ¨å‡½æ•°ä¸Šæ–¹åº”ç”¨ `@tool` è£…é¥°å™¨ã€‚
2. æ ¹æ®éœ€è¦è®¾ç½®è£…é¥°å™¨å‚æ•°ã€‚

ä½¿ç”¨è¿™ä¸ªè£…é¥°å™¨ï¼Œä½ å¯ä»¥è½»æ¾åœ°å°†å¸¸è§„ Python å‡½æ•°è½¬æ¢ä¸ºå¼ºå¤§çš„å·¥å…·ï¼Œä»è€Œå®ç°è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆå’Œçµæ´»çš„æ¥å£åˆ›å»ºã€‚


```python
from langchain.tools import tool


# Convert a function into a tool using a decorator.
@tool
def add_numbers(a: int, b: int) -> int:
    """Add two numbers"""
    return a + b


@tool
def multiply_numbers(a: int, b: int) -> int:
    """Multiply two numbers"""
    return a * b

# Execute tool.
print(add_numbers.invoke({"a": 3, "b": 4}))
print(multiply_numbers.invoke({"a": 3, "b": 4}))
```

## åˆ›å»ºä¸€ä¸ªç”¨äº Google æ–°é—»æ–‡ç« æœç´¢çš„è‡ªå®šä¹‰å·¥å…·

å®šä¹‰ `GoogleNews` ç±»ï¼Œè¯¥ç±»å°†ä½œä¸ºä¸€ä¸ªå·¥å…·ï¼Œç”¨äºæœç´¢ Google æ–°é—»æ–‡ç« ã€‚

**æ³¨æ„**
- ä¸éœ€è¦ API å¯†é’¥ï¼ˆå› ä¸ºå®ƒä½¿ç”¨ RSS æºï¼‰ã€‚

æ­¤å·¥å…·ç”¨äºæœç´¢ç”± **news.google.com** æä¾›çš„æ–°é—»æ–‡ç« ã€‚

**æè¿°**
- ä½¿ç”¨ Google æ–°é—»æœç´¢ API æ¥æ£€ç´¢æœ€æ–°çš„æ–°é—»ã€‚
- å…è®¸åŸºäºå…³é”®è¯æœç´¢æ–°é—»ã€‚

**ä¸»è¦å‚æ•°**
- `k` (int)ï¼šè¿”å›çš„æœ€å¤§æœç´¢ç»“æœæ•°ï¼ˆé»˜è®¤ï¼š5ï¼‰ã€‚

```python
# hl: è¯­è¨€, gl: åŒºåŸŸ, ceid: åŒºåŸŸå’Œè¯­è¨€ä»£ç 
url = f"{self.base_url}?hl=en&gl=US&ceid=US:en" 
```

åœ¨ä»£ç ä¸­ï¼Œä½ å¯ä»¥é€šè¿‡ä¿®æ”¹è¯­è¨€ (hl)ã€åŒºåŸŸ (gl) å’ŒåŒºåŸŸä¸è¯­è¨€ä»£ç  (ceid) æ¥è°ƒæ•´æœç´¢ç»“æœçš„è¯­è¨€å’ŒåŒºåŸŸã€‚

**æ³¨æ„**

å°†æä¾›çš„ä»£ç ä¿å­˜ä¸º `google_news.py`ï¼Œç„¶åä½ å¯ä»¥åœ¨å…¶ä»–æ–‡ä»¶ä¸­ä½¿ç”¨ `from google_news import GoogleNews` è¿›è¡Œå¯¼å…¥ã€‚


```python
import feedparser
from urllib.parse import quote
from typing import List, Dict, Optional


class GoogleNews:
    """
    This is a class for searching Google News and returning the results.
    """

    def __init__(self):
        """
        Initializes the GoogleNews class.
        Sets the base_url attribute.
        """
        self.base_url = "https://news.google.com/rss"

    def _fetch_news(self, url: str, k: int = 3) -> List[Dict[str, str]]:
        """
        Fetches news from the given URL.

        Args:
            url (str): The URL to fetch the news from.
            k (int): The maximum number of news articles to fetch (default: 3).

        Returns:
            List[Dict[str, str]]: A list of dictionaries containing news titles and links.
        """
        news_data = feedparser.parse(url)
        return [
            {"title": entry.title, "link": entry.link}
            for entry in news_data.entries[:k]
        ]

    def _collect_news(self, news_list: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        Formats and returns the list of news articles.

        Args:
            news_list (List[Dict[str, str]]): A list of dictionaries containing news information.

        Returns:
            List[Dict[str, str]]: A list of dictionaries containing URLs and content.
        """
        if not news_list:
            print("No news available for the given keyword.")
            return []

        result = []
        for news in news_list:
            result.append({"url": news["link"], "content": news["title"]})

        return result

    def search_latest(self, k: int = 3) -> List[Dict[str, str]]:
        """
        Searches for the latest news.

        Args:
            k (int): The maximum number of news articles to search for (default: 3).

        Returns:
            List[Dict[str, str]]: A list of dictionaries containing URLs and content.
        """
        #url = f"{self.base_url}?hl=ko&gl=KR&ceid=KR:ko"
        url = f"{self.base_url}?hl=en&gl=US&ceid=US:en" # hl: ì–¸ì–´, gl: ì§€ì—­, ceid: ì§€ì—­ ë° ì–¸ì–´ ì½”ë“œ
        news_list = self._fetch_news(url, k)
        return self._collect_news(news_list)

    def search_by_keyword(
        self, keyword: Optional[str] = None, k: int = 3
    ) -> List[Dict[str, str]]:
        """
        Searches for news using a keyword.  

        Args:
            keyword (Optional[str]): The keyword to search for (default: None).
            k (int): The maximum number of news articles to search for (default: 3).

        Returns:
            List[Dict[str, str]]: A list of dictionaries containing URLs and content.
        """
        if keyword:
            encoded_keyword = quote(keyword)
            url = f"{self.base_url}/search?q={encoded_keyword}"
        else:
            url = f"{self.base_url}?hl=en&gl=US&ceid=US:en"
        news_list = self._fetch_news(url, k)
        return self._collect_news(news_list)


google_tool = GoogleNews()
```


```python
google_tool.search_by_keyword("AI Investment")
```

åœ°å€æ˜¯ google çš„, å¾—ç¿»å¢™, ä»¥ä¸‹æ˜¯ç¤ºä¾‹ç»“æœ  
[{'url': 'https://news.google.com/rss/articles/CBMimAFBVV95cUxPNkFrLURMdEZWOV9zdmRrTUhNbVFkdWswZWx2Qmh4cTJlMmFIdmpsQ3doaVluenA3TEJaT0U3RWVmanl3TTQ5V3RfS3kyYVpydEloNWZXbjBmSF85MGR5cjNFSFI5eFhtTGdIVlNXX3UxNmxwMnVIb2NkTXA5WFVZR2hKLUw5RU9iT3k1Zno2UG10N2h1b2g5Sw?oc=5',
  'content': 'Nvidia Calls China\'s DeepSeek an "Excellent AI Advancement": Should Investors Press the Buy Button? - The Motley Fool'},
 {'url': 'https://news.google.com/rss/articles/CBMikwFBVV95cUxPd2ZnMnNwSWo2ZGhVSUJuNHd5S1Y3WUNWSkM4a0h5aHZQWU8tdzdlaW9pb25RUnI2cEwyZGtTemo5VUgwTDNHLVppNkw2MXdsbTRnb0UteHhtaHgxV043ZE9ZeG5aLUlCTzBGSHc1TFJzaHJsZENObzMxdTlvaEcyaG9vSjlRSTFWYXJEelF6RkRETnc?oc=5',
  'content': 'How DeepSeek is upending AI innovation and investment after sending tech leaders reeling - New York Post'},
 {'url': 'https://news.google.com/rss/articles/CBMivwFBVV95cUxNUGdjLVE5dFpLaVZOcFY1djBRQXBLeTNZalptNmstNXlWRkpvX1U2aTJ5cDNiS3RNT2JzeGI1SnlzTXIyS2dWcEdieDB4R1kxSEo2eXUydlRkVWlzOGdUTnVCQ2NwNjNjaFpCdVpxQkphZXYxLU9BaXhBWmdVYWVjQnY1N3Q1aUtqaER5LV9WVlNWZ3BXMk5WR0gwWnlIU3RIazJZelZJQUM1ek12ZDFodEg1eDFaRm56eTR5UEh3VQ?oc=5',
  'content': 'DeepSeek Marks The End Of The First Phase Of The AI Investment Boom - Forbes'}]

å†ç”¨ tool è£…é¥°å™¨


```python
from langchain.tools import tool
from typing import List, Dict


# Create a tool for searching news by keyword
@tool
def search_keyword(query: str) -> List[Dict[str, str]]:
    """Look up news by keyword"""
    print(query)
    news_tool = GoogleNews()
    return news_tool.search_by_keyword(query, k=5)

	
# Execution Results
search_keyword.invoke({"query": "LangChain AI"})
```

# bind_tools

`bind_tools` æ˜¯ LangChain ä¸­çš„ä¸€ä¸ªå¼ºå¤§åŠŸèƒ½ï¼Œç”¨äºå°†è‡ªå®šä¹‰å·¥å…·ä¸å¤§è¯­è¨€æ¨¡å‹ (LLMs) é›†æˆï¼Œä»è€Œå®ç°å¢å¼ºçš„ AI å·¥ä½œæµã€‚

æ¥ä¸‹æ¥å±•ç¤ºå¦‚ä½•åˆ›å»ºã€ç»‘å®šå·¥å…·ã€è§£æå¹¶æ‰§è¡Œè¾“å‡ºï¼Œå¹¶å°†å®ƒä»¬é›†æˆåˆ° `AgentExecutor` ä¸­ã€‚

![](https://python.langchain.com/assets/images/tool_calling_components-bef9d2bcb9d3706c2fe58b57bf8ccb60.png)


```python
import requests
from bs4 import BeautifulSoup
from langchain_core.tools import tool


# Define the tools
@tool
def get_word_length(word: str) -> int:
    """Return the length of the given text"""
    return len(word)


@tool
def add_function(a: float, b: float) -> float:
    """Add two numbers together"""
    return a + b
	

tools = [get_word_length, add_function]
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ `bind_tools` å‡½æ•°å°†å®šä¹‰çš„å·¥å…·ä¸ç‰¹å®šçš„å¤§è¯­è¨€æ¨¡å‹ (LLM) å…³è”èµ·æ¥ã€‚


```python
from langchain_openai import ChatOpenAI

# Create a model
llm = ChatOpenAI(
	base_url='http://localhost:5551/v1',
	api_key='EMPTY',
	model_name='Qwen2.5-3B-Instruct',
	temperature=0.2,
)

# Tool binding
llm_with_tools = llm.bind_tools(tools)
```

è¿™æ˜¯ç»‘å®šå‡½æ•°çš„è¯´æ˜


```python
import json

print(json.dumps(llm_with_tools.kwargs, indent=2))
```


```python
llm_with_tools.invoke(
    "What is the length of the given text 'LangChain OpenTutorial'?"
)
```

ç»“æœå­˜å‚¨åœ¨ `tool_calls` ä¸­ã€‚è®©æˆ‘ä»¬æ‰“å° `tool_calls`ã€‚

[æ³¨æ„]

- `name` è¡¨ç¤ºå·¥å…·çš„åç§°ã€‚
- `args` åŒ…å«ä¼ é€’ç»™å·¥å…·çš„å‚æ•°ã€‚


```python
from pprint import pprint

# Execution result
ret = llm_with_tools.invoke(
    "What is the length of the given text 'LangChain OpenTutorial'?"
)

pprint(ret.__dict__)
print(20*'-')
pprint(ret.tool_calls)
```

## tool è¾“å‡ºè§£æ JsonOutputToolsParser

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŠŠ `llm_with_tools` ä¸ `JsonOutputToolsParser` è¿æ¥èµ·æ¥ï¼Œä»¥è§£æ `tool_calls` å¹¶æŸ¥çœ‹ç»“æœã€‚

- `type` è¡¨ç¤ºå·¥å…·çš„ç±»å‹ã€‚
- `args` åŒ…å«ä¼ é€’ç»™å·¥å…·çš„å‚æ•°ã€‚


```python
from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser

# Tool Binding + Tool Parser
chain = llm_with_tools | JsonOutputToolsParser(tools=tools)

# Execution Result
tool_call_results = chain.invoke(
    "What is the length of the given text 'LangChain OpenTutorial'?"
)
print(tool_call_results)
```

`execute_tool_calls` å‡½æ•°è¯†åˆ«åˆé€‚çš„å·¥å…·ï¼Œä¼ é€’ç›¸åº”çš„ `args`ï¼Œç„¶åæ‰§è¡Œè¯¥å·¥å…·ã€‚


```python
def execute_tool_calls(tool_call_results):
    """
    Function to execute the tool call results.

    :param tool_call_results: List of the tool call results
    :param tools: List of available tools
    """

    # Iterate over the list of the tool call results
    for tool_call_result in tool_call_results:
        # Tool name (function name)
        tool_name = tool_call_result["type"]
        # Tool arguments
        tool_args = tool_call_result["args"]

        # Find the tool that matches the name and execute it
        # Use the next() function to find the first matching tool
        matching_tool = next((tool for tool in tools if tool.name == tool_name), None)
        if matching_tool:
            # Execute the tool
            result = matching_tool.invoke(tool_args)
            print(
                f"[Executed Tool] {tool_name} [Args] {tool_args}\n[Execution Result] {result}"
            )
        else:
            print(f"Warning: Unable to find the tool corresponding to {tool_name}.")


# Execute the tool calls
execute_tool_calls(tool_call_results)
```

## å°†å·¥å…·ä¸è§£æå™¨ç»‘å®šä»¥æ‰§è¡Œ

è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†å·¥å…·ç»‘å®šã€è§£æç»“æœå’Œæ‰§è¡Œå·¥å…·è°ƒç”¨çš„æ•´ä¸ªè¿‡ç¨‹åˆå¹¶ä¸ºä¸€ä¸ªæ­¥éª¤ã€‚

- `llm_with_tools`ï¼šç»‘å®šå·¥å…·çš„LLMæ¨¡å‹ã€‚
- `JsonOutputToolsParser`ï¼šå¤„ç†å·¥å…·è°ƒç”¨ç»“æœçš„è§£æå™¨ã€‚
- `execute_tool_calls`ï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨ç»“æœçš„å‡½æ•°ã€‚

[æµç¨‹æ‘˜è¦]

1. å°†å·¥å…·ç»‘å®šåˆ°æ¨¡å‹ã€‚
2. è§£æå·¥å…·è°ƒç”¨çš„ç»“æœã€‚
3. æ‰§è¡Œå·¥å…·è°ƒç”¨çš„ç»“æœã€‚


```python
from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser

# bind_tools + Parser + Execution
chain = llm_with_tools | JsonOutputToolsParser(tools=tools) | execute_tool_calls
```


```python
chain.invoke("What is the length of the given text 'LangChain OpenTutorial'?")
```


```python
# Execution Result 2
chain.invoke("114.5 + 121.2")

# Double check
print(114.5 + 121.2)
```

## å°†å·¥å…·ä¸Agentå’Œ`AgentExecutor`ç»‘å®š

`bind_tools` æä¾›å¯ä»¥ç”±æ¨¡å‹ä½¿ç”¨çš„å·¥å…·ï¼ˆschemasï¼‰ã€‚

`AgentExecutor` åˆ›å»ºä¸€ä¸ªæ‰§è¡Œå¾ªç¯ï¼Œç”¨äºæ‰§è¡Œè¯¸å¦‚è°ƒç”¨LLMã€è·¯ç”±åˆ°åˆé€‚çš„å·¥å…·ã€æ‰§è¡Œå·¥å…·ä»¥åŠé‡æ–°è°ƒç”¨æ¨¡å‹ç­‰ä»»åŠ¡ã€‚


```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI

# Create an Agent prompt
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are very powerful assistant, but don't know current events",
        ),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ]
)

# Create a model
llm = ChatOpenAI(
	base_url='http://localhost:5551/v1',
	api_key='EMPTY',
	model_name='Qwen2.5-3B-Instruct',
	temperature=0.2,
)

```


```python
from langchain.agents import AgentExecutor, create_tool_calling_agent

# Use the tools defined previously
tools = [get_word_length, add_function]

# Create an Agent
agent = create_tool_calling_agent(llm, tools, prompt)

# Create an AgentExecutor
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    handle_parsing_errors=True,
)
```


```python
# Execute the Agent
result = agent_executor.invoke(
    {"input": "What is the length of the given text 'LangChain OpenTutorial'?"}
)

# Execution Result
print(result["output"])
```


```python
# Execute the Agent
result = agent_executor.invoke({"input": "Calculate the result of 114.5 + 121.2"})

# Execution Result
print(result["output"])
```

å°æ¨¡å‹çš„æ€§èƒ½è¿˜æ˜¯ä¼šå­˜åœ¨è§£æå’Œ reasoning æ–¹é¢çš„é”™è¯¯

# Tool Calling Agent

åœ¨ LangChain ä¸­ï¼Œ**å·¥å…·è°ƒç”¨**ï¼ˆtool callingï¼‰å…è®¸æ¨¡å‹æ£€æµ‹ä½•æ—¶è°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ª**å·¥å…·**ï¼Œä»¥åŠéœ€è¦å°†ä»€ä¹ˆè¾“å…¥ä¼ é€’ç»™è¿™äº›å·¥å…·ã€‚

åœ¨è¿›è¡Œ API è°ƒç”¨æ—¶ï¼Œä½ å¯ä»¥å®šä¹‰å·¥å…·ï¼Œå¹¶æ™ºèƒ½åœ°å¼•å¯¼æ¨¡å‹ç”Ÿæˆç»“æ„åŒ–å¯¹è±¡ï¼Œä¾‹å¦‚ JSONï¼Œè¿™äº›å¯¹è±¡åŒ…å«è°ƒç”¨è¿™äº›å·¥å…·æ‰€éœ€çš„å‚æ•°ã€‚

å·¥å…· API çš„ç›®æ ‡æ˜¯æä¾›æ¯”æ ‡å‡†çš„æ–‡æœ¬ç”Ÿæˆæˆ–èŠå¤© API æ›´åŠ å¯é çš„æœ‰æ•ˆå’Œæœ‰ç”¨çš„**å·¥å…·è°ƒç”¨**ç”Ÿæˆã€‚

ä½ å¯ä»¥åˆ›å»ºä»£ç†ï¼ˆagentsï¼‰ï¼Œè¿™äº›ä»£ç†ä¼šè¿­ä»£åœ°è°ƒç”¨å·¥å…·å¹¶æ¥æ”¶ç»“æœï¼Œç›´åˆ°é€šè¿‡æ•´åˆè¿™äº›ç»“æ„åŒ–è¾“å‡ºè§£å†³æŸ¥è¯¢ï¼Œå¹¶å°†å¤šä¸ªå·¥å…·ç»‘å®šåˆ°ä¸€ä¸ªå·¥å…·è°ƒç”¨çš„èŠå¤©æ¨¡å‹ï¼Œè®©æ¨¡å‹é€‰æ‹©è°ƒç”¨å“ªäº›å·¥å…·ã€‚

è¿™ä»£è¡¨äº†ä¸€ä¸ªæ›´åŠ **é€šç”¨çš„ç‰ˆæœ¬**ï¼Œå®ƒæ˜¯ä¸º OpenAI çš„ç‰¹å®šå·¥å…·è°ƒç”¨é£æ ¼è®¾è®¡çš„ OpenAI å·¥å…·ä»£ç†çš„æ‰©å±•ã€‚

è¿™ä¸ªä»£ç†ä½¿ç”¨ LangChain çš„ `ToolCall` æ¥å£ï¼Œæ”¯æŒæ¯” OpenAI æ›´å¹¿æ³›çš„æä¾›è€…å®ç°ï¼ŒåŒ…æ‹¬ `Anthropic`ã€`Google Gemini` å’Œ `Mistral` ç­‰ã€‚

![](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/15-Agent/assets/15-agent-agent-concept.png?raw=1)

## åˆ›å»ºå·¥å…·

LangChain å…è®¸ä½ å®šä¹‰è‡ªå®šä¹‰å·¥å…·ï¼Œä¾›ä½ çš„ä»£ç†ä¸ä¹‹äº¤äº’ã€‚ä½ å¯ä»¥åˆ›å»ºç”¨äºæœç´¢æ–°é—»æˆ–æ‰§è¡Œ Python ä»£ç çš„å·¥å…·ã€‚

`@tool` è£…é¥°å™¨ç”¨äºåˆ›å»ºå·¥å…·ï¼š
- `TavilySearchResults` æ˜¯ä¸€ä¸ªç”¨äºæœç´¢æ–°é—»çš„å·¥å…·ã€‚
- `PythonREPL` æ˜¯ä¸€ä¸ªç”¨äºæ‰§è¡Œ Python ä»£ç çš„å·¥å…·ã€‚


```python
from langchain.tools import tool
from typing import List, Dict, Annotated
from langchain_community.tools import TavilySearchResults
from langchain_experimental.utilities import PythonREPL


# Creating tool for searching news
@tool
def search_news(query: str) -> List[Dict[str, str]]:
    """Search news by input keyword using Tavily Search API"""
    news_tool = TavilySearchResults(
        max_results=3,
        include_answer=True,
        include_raw_content=True,
        include_images=True,
        # search_depth="advanced",
        # include_domains = [],
        # exclude_domains = []
    )
    return news_tool.invoke(query, k=3)


# Creating tool for executing python code
@tool
def python_repl_tool(
    code: Annotated[str, "The python code to execute to generate your chart."],
):
    """Use this tool to execute Python code. If you want to see the output of a value,
    you should print it using print(...). This output is visible to the user."""
    result = ""
    try:
        result = PythonREPL().run(code)
    except BaseException as e:
        print(f"Failed to execute. Error: {repr(e)}")
    finally:
        return result


print(f"Tool name: {search_news.name}")
print(f"Tool description: {search_news.description}")
print(f"Tool args: {search_news.args}")

print('-'*20)
print(f"Tool name: {python_repl_tool.name}")
print(f"Tool description: {python_repl_tool.description}")
print(f"Tool args: {python_repl_tool.args}")

```

    Tool name: search_news
    Tool description: Search news by input keyword using Tavily Search API
    Tool args: {'query': {'title': 'Query', 'type': 'string'}}
    --------------------
    Tool name: python_repl_tool
    Tool description: Use this tool to execute Python code. If you want to see the output of a value,
        you should print it using print(...). This output is visible to the user.
    Tool args: {'code': {'description': 'The python code to execute to generate your chart.', 'title': 'Code', 'type': 'string'}}



```python
search_news('2024')
```




    [{'url': 'https://en.wikipedia.org/wiki/2024_in_the_United_States',
      'content': "In the Senate, at least six seats, those of Senators Tom Carper from Delaware, Mike Braun from Indiana, Ben Cardin from Maryland, Debbie Stabenow from Michigan, Mitt Romney from Utah, and Joe Manchin from West Virginia, will be open contests; the seat of the late Dianne Feinstein is also expected to be an open contest with Feinstein's immediate replacement, Laphonza Butler, expected to serve on an interim basis.[1][2][3]\nConcerning state governments, 11 states and two territories will hold gubernatorial elections, and most states and territories will hold elections for their legislatures. Contents\n2024 in the United States\nThe following is a list of predicted and scheduled events of the year 2024 in the United States, that have not yet occurred.\n With former president Donald Trump's declaration to run for the office again, the election may possibly be a rematch of the 2020 election, although the June 2023 indictment of Donald Trump may have a significant impact on Trump's presidential campaign. In the federal government, the offices of the president, vice president, all 435 seats of the House of Representatives, and roughly one third of the Senate. â†\nâ†’\nElections[edit]\nThe US general elections will be held on November 5 of this year."},
     {'url': 'https://abcnews.go.com/Entertainment/abc-news-year-2024-back-years-major-news/story?id=116448091',
      'content': 'ABC News\' \'The Year: 2024\' looks back at this year\'s major news and entertainment events - ABC News ABC News ABC News\' \'The Year: 2024\' looks back at this year\'s major news and entertainment events As the world gears up for 2025, it leaves behind a year of war, political shifts, pop culture moments, sporting triumphs, lost stars and more. ABC News was there to chronicle every moment and will look back at this year\'s defining events in a two-hour special, "The Year: 2024," which airs Thursday, Dec. 26 at 9 p.m. ET, and streams afterwards on Hulu. The special also explores how the love lives of some of our favorite stars evolved this year. ABC News Live'},
     {'url': 'https://en.wikipedia.org/wiki/2024',
      'content': 'May 8 â€“ In North Macedonian elections, the right-wing party VMRO-DPMNE wins in a landslide in the parliamentary elections, while its presidential candidate Gordana Siljanovska-Davkova is elected as the first female president of the country in the second round of the presidential election.[88][89] July 13 â€“ While campaigning for the 2024 United States presidential election, former President Donald Trump is shot in the right ear in an assassination attempt at a rally he held near Butler, Pennsylvania.[139] July 28 â€“ 2024 Venezuelan presidential election: Incumbent President NicolÃ¡s Maduro declares victory against opposition candidate Edmundo GonzÃ¡lez Urrutia amid alleged irregularities, causing numerous South American states to refuse to acknowledge the results or suspend diplomatic relations with the Maduro government and sparking nationwide protests.[151]'}]




```python
# Creating tools
tools = [search_news, python_repl_tool]
```

## æ„å»ºä»£ç†æç¤º

- `chat_history`ï¼šæ­¤å˜é‡å­˜å‚¨å¯¹è¯å†å²è®°å½•ï¼Œå¦‚æœä½ çš„ä»£ç†æ”¯æŒå¤šè½®å¯¹è¯ï¼Œåˆ™ä½¿ç”¨æ­¤å˜é‡ã€‚ï¼ˆå¦åˆ™ï¼Œå¯ä»¥çœç•¥æ­¤é¡¹ã€‚ï¼‰
- `agent_scratchpad`ï¼šæ­¤å˜é‡ä½œä¸ºä¸´æ—¶å­˜å‚¨ï¼Œç”¨äºå­˜æ”¾ä¸­é—´å˜é‡ã€‚
- `input`ï¼šæ­¤å˜é‡ä»£è¡¨ç”¨æˆ·çš„è¾“å…¥ã€‚


```python
from langchain_core.prompts import ChatPromptTemplate

# Creating prompt
# Prompt is a text that describes the task the model should perform. (input the name and role of the tool)
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. "
            "Make sure to use the `search_news` tool for searching keyword related news.",
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)
```

## åˆ›å»ºä»£ç†

ä½¿ç”¨ `create_tool_calling_agent` å‡½æ•°å®šä¹‰ä¸€ä¸ªä»£ç†ã€‚


```python
from langchain_openai import ChatOpenAI
from langchain.agents import create_tool_calling_agent

# Creating LLM
llm = ChatOpenAI(
	base_url='http://localhost:5551/v1',
	api_key='EMPTY',
	model_name='Qwen2.5-3B-Instruct',
	temperature=0.2,
)

# Creating Agent
agent = create_tool_calling_agent(llm, tools, prompt)
```

## `AgentExecutor`

`AgentExecutor` æ˜¯ä¸€ä¸ªç”¨äºç®¡ç†ä½¿ç”¨å·¥å…·çš„ä»£ç†çš„ç±»ã€‚

**å…³é”®å±æ€§**
- `agent`ï¼šè´Ÿè´£åˆ›å»ºè®¡åˆ’å¹¶åœ¨æ‰§è¡Œå¾ªç¯çš„æ¯ä¸ªæ­¥éª¤ä¸­ç¡®å®šè¡ŒåŠ¨çš„åº•å±‚ä»£ç†ã€‚
- `tools`ï¼šåŒ…å«ä»£ç†è¢«æˆæƒä½¿ç”¨çš„æ‰€æœ‰æœ‰æ•ˆå·¥å…·çš„åˆ—è¡¨ã€‚
- `return_intermediate_steps`ï¼šå¸ƒå°”æ ‡å¿—ï¼Œå†³å®šæ˜¯å¦è¿”å›ä»£ç†åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æ‰€é‡‡å–çš„ä¸­é—´æ­¥éª¤ä»¥åŠæœ€ç»ˆè¾“å‡ºã€‚
- `max_iterations`ï¼šä»£ç†åœ¨æ‰§è¡Œå¾ªç¯ç»ˆæ­¢ä¹‹å‰å¯ä»¥é‡‡å–çš„æœ€å¤§æ­¥éª¤æ•°ã€‚
- `max_execution_time`ï¼šæ‰§è¡Œå¾ªç¯å…è®¸è¿è¡Œçš„æœ€é•¿æ—¶é—´ã€‚
- `early_stopping_method`ï¼šå®šä¹‰å½“ä»£ç†æœªè¿”å› `AgentFinish` æ—¶å¦‚ä½•å¤„ç†çš„æ–¹å¼ã€‚ï¼ˆ"force" æˆ– "generate"ï¼‰
  - `"force"`ï¼šè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæ‰§è¡Œå¾ªç¯ç”±äºè¾¾åˆ°æ—¶é—´æˆ–è¿­ä»£é™åˆ¶è€Œè¢«åœæ­¢ã€‚
  - `"generate"`ï¼šè°ƒç”¨ä»£ç†çš„ LLM é“¾ä¸€æ¬¡ï¼Œæ ¹æ®ä¹‹å‰çš„æ­¥éª¤ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚
- `handle_parsing_errors`ï¼šæŒ‡å®šå¦‚ä½•å¤„ç†è§£æé”™è¯¯ã€‚ï¼ˆå¯ä»¥è®¾ç½®ä¸º `True`ã€`False`ï¼Œæˆ–æä¾›è‡ªå®šä¹‰é”™è¯¯å¤„ç†å‡½æ•°ã€‚ï¼‰
- `trim_intermediate_steps`ï¼šä¿®å‰ªä¸­é—´æ­¥éª¤çš„æ–¹æ³•ã€‚ï¼ˆå¯ä»¥è®¾ç½®ä¸º `-1` ä»¥ä¿ç•™æ‰€æœ‰æ­¥éª¤ï¼Œæˆ–æä¾›è‡ªå®šä¹‰ä¿®å‰ªå‡½æ•°ã€‚ï¼‰

**å…³é”®æ–¹æ³•**
1. `invoke`ï¼šæ‰§è¡Œä»£ç†ã€‚
2. `stream`ï¼šæµå¼ä¼ è¾“è¾¾åˆ°æœ€ç»ˆè¾“å‡ºæ‰€éœ€çš„æ­¥éª¤ã€‚

**å…³é”®ç‰¹æ€§**
1. **å·¥å…·éªŒè¯**ï¼šç¡®ä¿å·¥å…·ä¸ä»£ç†å…¼å®¹ã€‚
2. **æ‰§è¡Œæ§åˆ¶**ï¼šè®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°å’Œæ‰§è¡Œæ—¶é—´é™åˆ¶æ¥ç®¡ç†ä»£ç†è¡Œä¸ºã€‚
3. **é”™è¯¯å¤„ç†**ï¼šæä¾›å¤šç§å¤„ç†è¾“å‡ºè§£æé”™è¯¯çš„é€‰é¡¹ã€‚
4. **ä¸­é—´æ­¥éª¤ç®¡ç†**ï¼šå…è®¸ä¿®å‰ªä¸­é—´æ­¥éª¤æˆ–è¿”å›è°ƒè¯•é€‰é¡¹ã€‚
5. **å¼‚æ­¥æ”¯æŒ**ï¼šæ”¯æŒå¼‚æ­¥æ‰§è¡Œå’Œç»“æœçš„æµå¼ä¼ è¾“ã€‚

**ä¼˜åŒ–å»ºè®®**
- è®¾ç½®é€‚å½“çš„ `max_iterations` å’Œ `max_execution_time` å€¼æ¥ç®¡ç†æ‰§è¡Œæ—¶é—´ã€‚
- ä½¿ç”¨ `trim_intermediate_steps` æ¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨ã€‚
- å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œä½¿ç”¨ `stream` æ–¹æ³•æ¥é€æ­¥ç›‘æ§ç»“æœã€‚


```python
from langchain.agents import AgentExecutor

# Create AgentExecutor
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=10,
    max_execution_time=10,
    handle_parsing_errors=True,
)

# Run AgentExecutor
result = agent_executor.invoke({"input": "Search news about AI Agent in 2025."})

print("Agent execution result:")
print(result["output"])
```

    
    
    [1m> Entering new AgentExecutor chain...[0m
    [32;1m[1;3m
    Invoking: `search_news` with `{'query': 'AI Agent 2025'}`
    
    
    [0m[36;1m[1;3m[{'url': 'https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks', 'content': 'According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance. I expect to see more focus on multimodal AI models in education, including in processing speech and images. AI Agents Work Together In 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI agents of diverse expertise work together. As an example, we recently introduced the\xa0Virtual Lab, where a professor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, open-ended research, with a human researcher providing high-level feedback. We will experience an emerging paradigm of research around how humans work together with AI agents.'}, {'url': 'https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/', 'content': 'AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents for the Enterprise will be the focus of 2025 To see what AI agents can do in 2025, letâ€™s consider a simple example: an email-answering tool. Letâ€™s improve our tool by building AI agents within a workflow. The Workflow of AI Agents: More Than Generative AI AI models can be connected or "chained" to build workflows where the output of one model becomes the input for the next. AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing 2025 - AI Agents for the Enterprise Follow me here on Forbes or on LinkedIn for more of my 2025 AI predictions.'}, {'url': 'https://www.godofprompt.ai/blog/ai-agents-you-cant-miss', 'content': 'Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.'}][0m[32;1m[1;3mHere are some relevant news articles about AI Agents in 2025:
    
    1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)
    
    2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on AI models being connected or "chained" to build workflows where the output of one model becomes the input for the next. It also mentions AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing.
    
    3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)
    
    These articles provide insights into the future of AI Agents, including their collaborative nature, their potential impact on enterprises, and the development of AI Agent Workflows.[0m
    
    [1m> Finished chain.[0m
    Agent execution result:
    Here are some relevant news articles about AI Agents in 2025:
    
    1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)
    
    2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on AI models being connected or "chained" to build workflows where the output of one model becomes the input for the next. It also mentions AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing.
    
    3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)
    
    These articles provide insights into the future of AI Agents, including their collaborative nature, their potential impact on enterprises, and the development of AI Agent Workflows.


## ä½¿ç”¨ Stream è¾“å‡ºæ£€æŸ¥é€æ­¥ç»“æœ

æˆ‘ä»¬å°†ä½¿ç”¨ `AgentExecutor` çš„ `stream()` æ–¹æ³•æ¥æµå¼ä¼ è¾“ä»£ç†çš„ä¸­é—´æ­¥éª¤ã€‚

`stream()` çš„è¾“å‡ºåœ¨ (Action, Observation) å¯¹ä¹‹é—´äº¤æ›¿ï¼Œæœ€ç»ˆå¦‚æœç›®æ ‡è¾¾æˆï¼Œå°†ä»¥ä»£ç†çš„ç­”æ¡ˆç»“æŸã€‚

æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š

1. Action è¾“å‡º
2. Observation è¾“å‡º
3. Action è¾“å‡º
4. Observation è¾“å‡º

...ï¼ˆç»§ç»­ç›´åˆ°ç›®æ ‡è¾¾æˆï¼‰...

ç„¶åï¼Œä»£ç†å°†åœ¨ç›®æ ‡è¾¾æˆåå¾—å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

ä»¥ä¸‹è¡¨æ ¼æ€»ç»“äº†ä½ å°†åœ¨è¾“å‡ºä¸­é‡åˆ°çš„å†…å®¹ï¼š

| è¾“å‡º | æè¿° |
|------|------|
| Action | `actions`ï¼šè¡¨ç¤º `AgentAction` æˆ–å…¶å­ç±»ã€‚<br>`messages`ï¼šä¸åŠ¨ä½œè°ƒç”¨å¯¹åº”çš„èŠå¤©æ¶ˆæ¯ã€‚ |
| Observation | `steps`ï¼šè®°å½•ä»£ç†çš„å·¥ä½œï¼ŒåŒ…æ‹¬å½“å‰çš„åŠ¨ä½œå’Œå…¶è§‚å¯Ÿç»“æœã€‚<br>`messages`ï¼šåŒ…å«å‡½æ•°è°ƒç”¨ç»“æœï¼ˆå³è§‚å¯Ÿç»“æœï¼‰çš„èŠå¤©æ¶ˆæ¯ã€‚ |
| Final Answer | `output`ï¼šè¡¨ç¤º `AgentFinish` ä¿¡å·ã€‚<br>`messages`ï¼šåŒ…å«æœ€ç»ˆè¾“å‡ºçš„èŠå¤©æ¶ˆæ¯ã€‚ |


```python
from langchain.agents import AgentExecutor

# Create AgentExecutor
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=False,
    handle_parsing_errors=True,
)

# Run in streaming mode
result = agent_executor.stream({"input": "Search news about AI Agent in 2025."})

for step in result:
    # Print intermediate steps
    print(step)
    print("===" * 20)
```

    {'actions': [ToolAgentAction(tool='search_news', tool_input={'query': 'AI Agent 2025'}, log="\nInvoking: `search_news` with `{'query': 'AI Agent 2025'}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'function': {'arguments': '{"query": "AI Agent 2025"}', 'name': 'search_news'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen2.5-3B-Instruct'}, id='run-a877dfea-5a20-4970-96da-0f3483298f7e', tool_calls=[{'name': 'search_news', 'args': {'query': 'AI Agent 2025'}, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'search_news', 'args': '{"query": "AI Agent 2025"}', 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='chatcmpl-tool-cf8525019f5847519566061e0e6647c6')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'function': {'arguments': '{"query": "AI Agent 2025"}', 'name': 'search_news'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen2.5-3B-Instruct'}, id='run-a877dfea-5a20-4970-96da-0f3483298f7e', tool_calls=[{'name': 'search_news', 'args': {'query': 'AI Agent 2025'}, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'search_news', 'args': '{"query": "AI Agent 2025"}', 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'index': 0, 'type': 'tool_call_chunk'}])]}
    ============================================================
    {'steps': [AgentStep(action=ToolAgentAction(tool='search_news', tool_input={'query': 'AI Agent 2025'}, log="\nInvoking: `search_news` with `{'query': 'AI Agent 2025'}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'function': {'arguments': '{"query": "AI Agent 2025"}', 'name': 'search_news'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen2.5-3B-Instruct'}, id='run-a877dfea-5a20-4970-96da-0f3483298f7e', tool_calls=[{'name': 'search_news', 'args': {'query': 'AI Agent 2025'}, 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'search_news', 'args': '{"query": "AI Agent 2025"}', 'id': 'chatcmpl-tool-cf8525019f5847519566061e0e6647c6', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='chatcmpl-tool-cf8525019f5847519566061e0e6647c6'), observation=[{'url': 'https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks', 'content': 'According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance. I expect to see more focus on multimodal AI models in education, including in processing speech and images. AI Agents Work Together In 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI agents of diverse expertise work together. As an example, we recently introduced the\xa0Virtual Lab, where a professor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, open-ended research, with a human researcher providing high-level feedback. We will experience an emerging paradigm of research around how humans work together with AI agents.'}, {'url': 'https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/', 'content': 'AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents for the Enterprise will be the focus of 2025 To see what AI agents can do in 2025, letâ€™s consider a simple example: an email-answering tool. Letâ€™s improve our tool by building AI agents within a workflow. The Workflow of AI Agents: More Than Generative AI AI models can be connected or "chained" to build workflows where the output of one model becomes the input for the next. AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing 2025 - AI Agents for the Enterprise Follow me here on Forbes or on LinkedIn for more of my 2025 AI predictions.'}, {'url': 'https://www.godofprompt.ai/blog/ai-agents-you-cant-miss', 'content': 'Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.'}])], 'messages': [FunctionMessage(content='[{"url": "https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks", "content": "According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance. I expect to see more focus on multimodal AI models in education, including in processing speech and images. AI Agents Work Together In 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI agents of diverse expertise work together. As an example, we recently introduced the\xa0Virtual Lab, where a professor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, open-ended research, with a human researcher providing high-level feedback. We will experience an emerging paradigm of research around how humans work together with AI agents."}, {"url": "https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/", "content": "AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents In 2025: What Enterprise Leaders Need To Know AI Agents for the Enterprise will be the focus of 2025 To see what AI agents can do in 2025, letâ€™s consider a simple example: an email-answering tool. Letâ€™s improve our tool by building AI agents within a workflow. The Workflow of AI Agents: More Than Generative AI AI models can be connected or \\"chained\\" to build workflows where the output of one model becomes the input for the next. AI Agent Workflows: Input - Orchestration - Control - Actions - Synthesizing 2025 - AI Agents for the Enterprise Follow me here on Forbes or on LinkedIn for more of my 2025 AI predictions."}, {"url": "https://www.godofprompt.ai/blog/ai-agents-you-cant-miss", "content": "Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike."}]', additional_kwargs={}, response_metadata={}, name='search_news')]}
    ============================================================
    {'output': 'Here are some relevant news articles about AI Agents in 2025:\n\n1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\n\n2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on how AI models can be connected or "chained" to build workflows where the output of one model becomes the input for the next.\n\n3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)\n\nThese articles provide insights into the expected trends and developments in AI Agents for both research and enterprise applications in the year 2025.', 'messages': [AIMessage(content='Here are some relevant news articles about AI Agents in 2025:\n\n1. [According to leading experts from Stanford Institute for Human-Centered AI, one major trend is the rise of collaborative AI systems where multiple specialized agents work together, with humans providing high-level guidance.](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\n\n2. [AI Agents In 2025: What Enterprise Leaders Need To Know](https://www.forbes.com/sites/lutzfinger/2025/01/05/ai-agents-in-2025-what-enterprise-leaders-need-to-know/) - This article discusses AI Agents for the Enterprise, focusing on how AI models can be connected or "chained" to build workflows where the output of one model becomes the input for the next.\n\n3. [Explore 10+ AI agents that are reshaping industries in 2025. From ChatGPT to DeepSeek-R1, discover how AI is becoming more intelligent, efficient, and essential for businesses and individuals alike.](https://www.godofprompt.ai/blog/ai-agents-you-cant-miss)\n\nThese articles provide insights into the expected trends and developments in AI Agents for both research and enterprise applications in the year 2025.', additional_kwargs={}, response_metadata={})]}
    ============================================================


## ä½¿ç”¨ç”¨æˆ·å®šä¹‰çš„å‡½æ•°è‡ªå®šä¹‰ä¸­é—´æ­¥éª¤è¾“å‡º

ä½ å¯ä»¥å®šä¹‰ä»¥ä¸‹ 3 ä¸ªå‡½æ•°æ¥è‡ªå®šä¹‰ä¸­é—´æ­¥éª¤çš„è¾“å‡ºï¼š

- `tool_callback`ï¼šæ­¤å‡½æ•°å¤„ç†å·¥å…·è°ƒç”¨ç”Ÿæˆçš„è¾“å‡ºã€‚
- `observation_callback`ï¼šæ­¤å‡½æ•°å¤„ç†è§‚å¯Ÿæ•°æ®è¾“å‡ºã€‚
- `result_callback`ï¼šæ­¤å‡½æ•°å…è®¸ä½ å¤„ç†æœ€ç»ˆç­”æ¡ˆçš„è¾“å‡ºã€‚


```python
from typing import Dict, Any


# Create AgentStreamParser class
class AgentStreamParser:
    def __init__(self):
        pass

    def tool_callback(self, tool: Dict[str, Any]) -> None:
        print("\n=== Tool Called ===")
        print(f"Tool: {tool.get('tool')}")
        print(f"Input: {tool.get('tool_input')}")
        print("==================\n")

    def observation_callback(self, step: Dict[str, Any]) -> None:
        print("\n=== Observation ===")
        observation_data = step["steps"][0].observation
        print(f"Observation: {observation_data}")
        print("===================\n")

    def result_callback(self, result: str) -> None:
        print("\n=== Final Answer ===")
        print(result)
        print("====================\n")

    def process_agent_steps(self, step: Dict[str, Any]) -> None:
        if "actions" in step:
            for action in step["actions"]:
                self.tool_callback(
                    {"tool": action.tool, "tool_input": action.tool_input}
                )
        elif "output" in step:
            self.result_callback(step["output"])
        else:
            self.observation_callback(step)


# Create AgentStreamParser instance
agent_stream_parser = AgentStreamParser()
```


```python
# Run in streaming mode
result = agent_executor.stream({"input": "Generate a array from 0 to 1 with the stride of 0.1 using numpy."})
# result = agent_executor.stream({"input": "Search news about AI Agent in 2025."})


for step in result:
    agent_stream_parser.process_agent_steps(step)
```

    
    === Tool Called ===
    Tool: numpy_array_generator
    Input: {'start': 1, 'step': 0.1}
    ==================
    
    
    === Observation ===
    Observation: numpy_array_generator is not a valid tool, try one of [search_news, python_repl_tool].
    ===================
    
    
    === Tool Called ===
    Tool: python_repl_tool
    Input: {'code': 'import numpy as np\nnp.arange(0, 1, 0.1)'}
    ==================
    
    
    === Observation ===
    Observation: 
    ===================
    
    
    === Tool Called ===
    Tool: python_repl_tool
    Input: {'code': 'import numpy as np\nnp.arange(0, 1, 0.1)'}
    ==================
    
    
    === Observation ===
    Observation: 
    ===================
    
    
    === Tool Called ===
    Tool: python_repl_tool
    Input: {'code': 'import numpy as np\nnp.arange(0, 1, 0.1)'}
    ==================
    
    
    === Observation ===
    Observation: 
    ===================
    
    
    === Final Answer ===
    The numpy array from 0 to 1 with a stride of 0.1 has been successfully generated. Here it is:
    
    ```
    array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ```
    
    Is there anything else I can assist you with?
    ====================
    


## ä¸ä¹‹å‰çš„å¯¹è¯å†å²è¿›è¡Œä»£ç†é€šä¿¡

ä¸ºäº†è®°ä½è¿‡å»çš„å¯¹è¯ï¼Œä½ å¯ä»¥å°† `AgentExecutor` åŒ…è£…åœ¨ `RunnableWithMessageHistory` ä¸­ã€‚

æœ‰å…³ `RunnableWithMessageHistory` çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚é˜…ä»¥ä¸‹é“¾æ¥ã€‚

**å‚è€ƒ**
- [LangChain Python API Reference > langchain: 0.3.14 > core > runnables > langchain_core.runnables.history > RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)


```python
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# Create a dictionary to store session_id
store = {}


# Function to get session history based on session_id
def get_session_history(session_ids):
    if session_ids not in store:  # If session_id is not in store
        # Create a new ChatMessageHistory object and store it in store
        store[session_ids] = ChatMessageHistory()
    return store[session_ids]  # Return session history for the corresponding session_id


# Create an agent with chat message history
agent_with_chat_history = RunnableWithMessageHistory(
    agent_executor,
    # Chat session_id
    get_session_history,
    # The key for the question input in the prompt: "input"
    input_messages_key="input",
    # The key for the message input in the prompt: "chat_history"
    history_messages_key="chat_history",
)
```


```python
# Request streaming output for the query
response = agent_with_chat_history.stream(
    {"input": "Hello! My name is Teddy!"},
    # Set session_id
    config={"configurable": {"session_id": "abc123"}},
)

# Check the output
for step in response:
    agent_stream_parser.process_agent_steps(step)
```

    
    === Final Answer ===
    Hello Teddy! It's nice to meet you. How can I assist you today? Do you have any specific questions or topics you'd like to explore?
    ====================
    



```python
# Request streaming output for the query
response = agent_with_chat_history.stream(
    {"input": "What is my name?"},
    # Set session_id
    config={"configurable": {"session_id": "abc123"}},
)

# Check the output
for step in response:
    agent_stream_parser.process_agent_steps(step)
```

    
    === Final Answer ===
    It seems like you've already provided your name as Teddy. If you have any other questions or need information about something else, feel free to ask!
    ====================
    



```python
# Request streaming output for the query
response = agent_with_chat_history.stream(
    {
        "input": "My email address is teddy@teddynote.com. The company name is TeddyNote Co., Ltd."
    },
    # Set session_id
    config={"configurable": {"session_id": "abc123"}},
)

# Check the output
for step in response:
    agent_stream_parser.process_agent_steps(step)
```

    
    === Tool Called ===
    Tool: search_news
    Input: {'query': 'TeddyNote Co., Ltd.'}
    ==================
    
    
    === Observation ===
    Observation: [{'url': 'https://www.youtube.com/@teddynote', 'content': 'ë°ì´í„° ë¶„ì„, ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, LLM ì— ëŒ€í•œ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì—°êµ¬ë³´ë‹¤ëŠ” ê°œë°œì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤ ğŸ™‡\u200dâ™‚ï¸ğŸ”¥ "í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸" ë­ì²´ì¸'}, {'url': 'https://github.com/teddynote', 'content': 'By company size. Enterprises Small and medium teams Startups Nonprofits By use case. DevSecOps DevOps CI/CD View all use cases By industry ... teddynote.github.io teddynote.github.io Public. Forked from mmistakes/minimal-mistakes. ğŸ“ Jekyll theme for building a personal site, blog, project documentation, or portfolio.'}, {'url': 'https://github.com/teddylee777', 'content': 'Jupyter Notebook\n1\n4\nConv2d and MaxPool2d Calculator for PyTorch\nPython\n18\n1\nStreamlit íŠœí† ë¦¬ì–¼ ğŸ˜\nJupyter Notebook\n13\n12\nì£¼ê°€ ì¢…ëª© íŒ¨í„´ ë°œêµ´ê¸°\nJupyter Notebook\n14\n12\n586\ncontributions\nin the last year\nContribution activity\nJanuary 2024\nSeeing something unexpected? Teddy Lee\nteddylee777\nAchievements\nAchievements\nHighlights\nBlock or report teddylee777\nPrevent this user from interacting with your repositories and sending you notifications.\n Jupyter Notebook\n58\n16\nForked from lovedlim/tensorflow\ní…ì„œí”Œë¡œ ë„ì„œ ì˜ˆì œ íŒŒì¼ì…ë‹ˆë‹¤.\n Samsung Electronics\ní…Œë””ë…¸íŠ¸ Blog\ní…Œë””ë…¸íŠ¸ YouTube\n@teddynote\nLinkedIn\nğŸ’» (This repository is intented for helping whom are interested in machine learning study)\nJupyter Notebook\n2.3k\n789\në¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹(PyTorch, TensorFlow) ì „ìš© ë„ì»¤ì…ë‹ˆë‹¤.'}]
    ===================
    
    
    === Final Answer ===
    Here are some recent news and information related to your company, TeddyNote Co., Ltd.:
    
    1. **TeddyNote Co., Ltd. on YouTube**: They have a YouTube channel where they discuss topics related to data analysis, machine learning, deep learning, and Large Language Models (LLM). They seem to have a focus on development rather than research. You can check out their channel [here](https://www.youtube.com/@teddynote).
    
    2. **TeddyNote Co., Ltd. on GitHub**: 
       - **Company Size**: They cater to small and medium-sized teams, startups, and nonprofits.
       - **Use Cases**: They support DevSecOps and DevOps, CI/CD.
       - **Public Repository**: You can view their public repository [here](https://github.com/teddynote).
       - **Personal Site**: They have a personal site and blog available at [teddynote.github.io](https://teddynote.github.io/).
       - **Contributions**: They have contributed to various projects, including a Jupyter Notebook for a Conv2d and MaxPool2d Calculator for PyTorch, a Streamlit tutorial, and a stock price pattern analysis tool. You can see their contributions [here](https://github.com/teddylee777).
    
    3. **TeddyLee777 on GitHub**: This is likely a personal GitHub account associated with TeddyNote Co., Ltd. They have contributed to various projects, including a TensorFlow book example repository and a Docker image for machine learning study.
    
    If you need more detailed information or have any specific questions about these resources, feel free to ask!
    ====================
    



```python
# Request streaming output for the query
response = agent_with_chat_history.stream(
    {
        "input": "Search the latest news and write it as the body of the email. "
        "The recipient is `Ms. Sally` and the sender is my personal information."
        "Write in a polite tone, and include appropriate greetings and closings at the beginning and end of the email."
    },
    # Set session_id
    config={"configurable": {"session_id": "abc123"}},
)

# Check the output
for step in response:
    agent_stream_parser.process_agent_steps(step)
```

    
    === Tool Called ===
    Tool: search_news
    Input: {'query': 'TeddyNote Co., Ltd latest news'}
    ==================
    
    
    === Tool Called ===
    Tool: python_repl_tool
    Input: {'code': 'import email; from email.mime.multipart import MIMEMultipart; from email.mime.text import MIMEText; msg = MIMEMultipart(); msg[\'From\'] = \'teddy@teddynote.com\'; msg[\'To\'] = \'sally@example.com\'; msg[\'Subject\'] = \'Latest News from TeddyNote Co., Ltd\'; body = """Here are the latest news and updates from TeddyNote Co., Ltd.:\n\n1. **TeddyNote Co., Ltd. on YouTube**: They have a YouTube channel where they discuss topics related to data analysis, machine learning, deep learning, and Large Language Models (LLM). They seem to have a focus on development rather than research. You can check out their channel [here](https://www.youtube.com/@teddynote).\n\n2. **TeddyNote Co., Ltd. on GitHub**: \n   - **Company Size**: They cater to small and medium-sized teams, startups, and nonprofits.\n   - **Use Cases**: They support DevSecOps and DevOps, CI/CD.\n   - **Public Repository**: You can view their public repository [here](https://github.com/teddynote).\n   - **Personal Site**: They have a personal site and blog available at [teddynote.github.io](https://teddynote.github.io/).\n   - **Contributions**: They have contributed to various projects, including a Jupyter Notebook for a Conv2d and MaxPool2d Calculator for PyTorch, a Streamlit tutorial, and a stock price pattern analysis tool. You can see their contributions [here](https://github.com/teddylee777).\n\n3. **TeddyLee777 on GitHub**: This is likely a personal GitHub account associated with TeddyNote Co., Ltd. They have contributed to various projects, including a TensorFlow book example repository and a Docker image for machine learning study.\n\nIf you need more detailed information or have any specific questions about these resources, feel free to ask!"""; msg.attach(MIMEText(body, \'plain\')); return msg.as_string()'}
    ==================
    
    
    === Tool Called ===
    Tool: send_email
    Input: {'to': 'sally@example.com', 'subject': 'Latest News from TeddyNote Co., Ltd', 'body': '...', 'sender': 'teddy@teddynote.com'}
    ==================
    
    
    === Tool Called ===
    Tool: email_status
    Input: {'email_id': '...'}
    ==================
    
    
    === Observation ===
    Observation: [{'url': 'https://www.threads.net/@teddynote', 'content': '60 Followers â€¢ 44 Threads â€¢ ë°ì´í„° & AI. See the latest conversations with @teddynote.'}, {'url': 'https://github.com/teddylee777', 'content': 'Jupyter Notebook\n1\n4\nConv2d and MaxPool2d Calculator for PyTorch\nPython\n18\n1\nStreamlit íŠœí† ë¦¬ì–¼ ğŸ˜\nJupyter Notebook\n13\n12\nì£¼ê°€ ì¢…ëª© íŒ¨í„´ ë°œêµ´ê¸°\nJupyter Notebook\n14\n12\n586\ncontributions\nin the last year\nContribution activity\nJanuary 2024\nSeeing something unexpected? Teddy Lee\nteddylee777\nAchievements\nAchievements\nHighlights\nBlock or report teddylee777\nPrevent this user from interacting with your repositories and sending you notifications.\n Jupyter Notebook\n58\n16\nForked from lovedlim/tensorflow\ní…ì„œí”Œë¡œ ë„ì„œ ì˜ˆì œ íŒŒì¼ì…ë‹ˆë‹¤.\n Samsung Electronics\ní…Œë””ë…¸íŠ¸ Blog\ní…Œë””ë…¸íŠ¸ YouTube\n@teddynote\nLinkedIn\nğŸ’» (This repository is intented for helping whom are interested in machine learning study)\nJupyter Notebook\n2.3k\n789\në¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹(PyTorch, TensorFlow) ì „ìš© ë„ì»¤ì…ë‹ˆë‹¤.'}, {'url': 'https://langchain-opentutorial.gitbook.io/langchain-opentutorial/15-agent/03-agent', 'content': 'Best regards, Teddy teddy@teddynote.com TeddyNote Co., Ltd. --- Feel free to modify any part of the email as you see fit! >>>>>'}]
    ===================
    
    
    === Observation ===
    Observation: SyntaxError("'return' outside function", ('<string>', 14, 152, None, 14, 174))
    ===================
    
    
    === Observation ===
    Observation: send_email is not a valid tool, try one of [search_news, python_repl_tool].
    ===================
    
    
    === Observation ===
    Observation: email_status is not a valid tool, try one of [search_news, python_repl_tool].
    ===================
    
    
    === Final Answer ===
    It seems there was an issue with the previous steps. Let's proceed with creating the email body using the news and information we gathered. Here is the body of the email:
    
    ---
    
    Hello Ms. Sally,
    
    I hope this email finds you well. I wanted to share some recent news and updates from TeddyNote Co., Ltd.:
    
    1. **TeddyNote Co., Ltd. on YouTube**: They have a YouTube channel where they discuss topics related to data analysis, machine learning, deep learning, and Large Language Models (LLM). They seem to have a focus on development rather than research. You can check out their channel [here](https://www.youtube.com/@teddynote).
    
    2. **TeddyNote Co., Ltd. on GitHub**:
       - **Company Size**: They cater to small and medium-sized teams, startups, and nonprofits.
       - **Use Cases**: They support DevSecOps and DevOps, CI/CD.
       - **Public Repository**: You can view their public repository [here](https://github.com/teddynote).
       - **Personal Site**: They have a personal site and blog available at [teddynote.github.io](https://teddynote.github.io/).
       - **Contributions**: They have contributed to various projects, including a Jupyter Notebook for a Conv2d and MaxPool2d Calculator for PyTorch, a Streamlit tutorial, and a stock price pattern analysis tool. You can see their contributions [here](https://github.com/teddylee777).
    
    3. **TeddyLee777 on GitHub**: This is likely a personal GitHub account associated with TeddyNote Co., Ltd. They have contributed to various projects, including a TensorFlow book example repository and a Docker image for machine learning study.
    
    If you need more detailed information or have any specific questions about these resources, feel free to ask!
    
    Best regards,
    Teddy
    teddy@teddynote.com
    TeddyNote Co., Ltd.
    
    ---
    
    Please let me know if you need any further assistance or if there are any specific details you would like to include.
    ====================
    


# Agentic RAG

**Agentic RAG** æ‰©å±•äº†ä¼ ç»Ÿçš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿï¼Œé€šè¿‡ç»“åˆåŸºäºä»£ç†çš„æ–¹æ³•ï¼Œå®ç°æ›´å¤æ‚çš„ä¿¡æ¯æ£€ç´¢å’Œå“åº”ç”Ÿæˆã€‚è¯¥ç³»ç»Ÿä¸ä»…ä»…å±€é™äºç®€å•çš„æ–‡æ¡£æ£€ç´¢å’Œå“åº”ç”Ÿæˆï¼Œè¿˜å…è®¸ä»£ç†åˆ©ç”¨å„ç§å·¥å…·è¿›è¡Œæ›´æ™ºèƒ½çš„ä¿¡æ¯å¤„ç†ã€‚è¿™äº›å·¥å…·åŒ…æ‹¬ç”¨äºè®¿é—®æœ€æ–°ä¿¡æ¯çš„ `Tavily Search`ã€æ‰§è¡Œ Python ä»£ç çš„èƒ½åŠ›ä»¥åŠè‡ªå®šä¹‰åŠŸèƒ½å®ç°ï¼Œæ‰€æœ‰è¿™äº›éƒ½é›†æˆåœ¨ `LangChain` æ¡†æ¶ä¸­ï¼Œä¸ºä¿¡æ¯å¤„ç†å’Œç”Ÿæˆä»»åŠ¡æä¾›å…¨é¢çš„è§£å†³æ–¹æ¡ˆã€‚

æœ¬æ•™ç¨‹æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿï¼Œä½¿ç”¨ `FAISS DB` æ¥æœ‰æ•ˆåœ°å¤„ç†å’Œæœç´¢ PDF æ–‡æ¡£ã€‚ä»¥è½¯ä»¶æ”¿ç­–ç ”ç©¶æ‰€çš„ AI Brief ä¸ºç¤ºä¾‹æ–‡æ¡£ï¼Œæˆ‘ä»¬å°†æ¢ç´¢å¦‚ä½•å°†åŸºäº Web çš„æ–‡æ¡£åŠ è½½å™¨ã€æ–‡æœ¬æ‹†åˆ†å™¨ã€å‘é‡å­˜å‚¨å’Œ `OpenAI` åµŒå…¥ç»“åˆèµ·æ¥ï¼Œåˆ›å»ºä¸€ä¸ªå®é™…çš„ **Agentic RAG** ç³»ç»Ÿã€‚è¯¥å®ç°å±•ç¤ºäº†å¦‚ä½•å°† `Retriever` å·¥å…·ä¸å„ç§ `LangChain` ç»„ä»¶æœ‰æ•ˆç»“åˆï¼Œåˆ›å»ºä¸€ä¸ªå¼ºå¤§çš„æ–‡æ¡£æœç´¢å’Œå“åº”ç”Ÿæˆç®¡é“ã€‚

## åˆ›å»ºå·¥å…·


```python
from langchain_community.tools.tavily_search import TavilySearchResults

# Create a search tool instance that returns up to 6 results
search = TavilySearchResults(k=6)
```


```python
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import DashScopeEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.tools.retriever import create_retriever_tool

# Load and process the PDF
loader = PyPDFLoader("data/What-is-AI.pdf")

# Create text splitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)


# Split the document
split_docs = loader.load_and_split(text_splitter)

# Create vector store
embeddings = DashScopeEmbeddings(
    model="text-embedding-v2",
)
vector = FAISS.from_documents(split_docs, embeddings)

# Create retriever
retriever = vector.as_retriever()

# Create retriever tool
retriever_tool = create_retriever_tool(
    retriever,
    name="pdf_search",
    description="use this tool to search information from the PDF document",
)
```

## åˆ›å»ºä»£ç†


```python
tools = [search, retriever_tool]
```


```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents import create_tool_calling_agent, AgentExecutor

# Initialize LLM
llm = ChatOpenAI(
	base_url='http://localhost:5551/v1',
	api_key='EMPTY',
	model_name='Qwen2.5-3B-Instruct',
	temperature=0.2,
)

# Define prompt template
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. "
            "Make sure to use the `pdf_search` tool for searching information from the PDF document. "
            "If you can't find the information from the PDF document, use the `search` tool for searching information from the web.",
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

# Create agent
agent = create_tool_calling_agent(llm, tools, prompt)

# Create agent executor
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)
```

## å¯¹è¯å†å²


```python
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# Create a store for session histories
store = {}


def get_session_history(session_ids):
    if session_ids not in store:
        store[session_ids] = ChatMessageHistory()
    return store[session_ids]


# Create agent with chat history
agent_with_chat_history = RunnableWithMessageHistory(
    agent_executor,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history",
)
```


```python
def process_response(response):
    """
    Process and display streaming response from the agent.

    Args:
        response: Agent's streaming response iterator
    """
    for chunk in response:
        if chunk.get("output"):
            print(chunk["output"])
        elif chunk.get("actions"):
            for action in chunk["actions"]:
                print(f"\nTool Used: {action.tool}")
                print(f"Tool Input: {action.tool_input}")
                if action.log:
                    print(f"Tool Log: {action.log}")
```


```python
# Example 1: Searching in PDF
response = agent_with_chat_history.stream(
    {
        "input": "What information can you find about Samsung's AI model in the document?"
    },
    config={"configurable": {"session_id": "tutorial_session_1"}},
)
process_response(response)
```

    
    Tool Used: pdf_search
    Tool Input: {'query': 'Samsung AI model'}
    Tool Log: 
    Invoking: `pdf_search` with `{'query': 'Samsung AI model'}`
    
    
    
    
    Tool Used: search
    Tool Input: {'query': 'Samsung AI model'}
    Tool Log: 
    Invoking: `search` with `{'query': 'Samsung AI model'}`
    responded: The provided text does not contain specific information about Samsung's AI model. It seems to be a general introduction to AI, its components, and some real-world applications. To find information about Samsung's AI model, we might need to look for more detailed or specific documents or articles. Let me try searching the web for more relevant information.
    
    
    
    
    Tool Used: tavily_search_results_json
    Tool Input: {'query': 'Samsung AI model'}
    Tool Log: 
    Invoking: `tavily_search_results_json` with `{'query': 'Samsung AI model'}`
    responded: It appears that the 'search' tool is not available. Let's try using the 'tavily_search_results_json' tool to search the web for information about Samsung's AI model.
    
    
    
    
    The search results provide information about Samsung's AI model, specifically Samsung Gauss 2, which is described as a new GenAI model that improves Galaxy AI performance and efficiency. Here are some key points from the search results:
    
    1. **Samsung Gauss 2**: This model supports 9 to 14 human languages and several programming languages. Samsung claims that Balanced and Supreme models match or beat other AI models on tasks.
    
    2. **Galaxy S25 Series**: The Galaxy S25 series features advanced, efficient AI image processing with ProScaler11, achieving a 40% improvement in display image scaling quality. It also incorporates custom technology with Samsungâ€™s mobile Digital Natural Image engine (mDNIe) embedded within the processor using Galaxy IP to enable greater display power efficiency.
    
    3. **Galaxy AI**: Samsung's Galaxy AI is described as a set of generative AI tools that brings features like live translation, generative photo editing, and more. The AI features are available on newer Samsung phones, but Samsung is making efforts to support these features on older models as well.
    
    4. **Samsung Gauss 2 on Device**: Samsung Gauss 2 is an on-device AI model, which means it processes data locally on the device rather than sending it to a cloud server.
    
    These results suggest that Samsung Gauss 2 is a significant advancement in their AI capabilities, particularly in improving Galaxy AI performance and efficiency. If you need more detailed information, you might want to look into the specific features and capabilities of Samsung Gauss 2 in more detail.



```python
# Example 1: Searching in PDF
response = agent_with_chat_history.stream(
    {
        "input": "List the devices using ai in your previous responese."
    },
    config={"configurable": {"session_id": "tutorial_session_1"}},
)
process_response(response)
```

    
    Tool Used: pdf_search
    Tool Input: {'query': 'devices using ai'}
    Tool Log: 
    Invoking: `pdf_search` with `{'query': 'devices using ai'}`
    
    
    
    Based on the information provided in the document, the devices mentioned that use AI are:
    
    1. **Smartphones**: The document mentions that AI is available on newer Samsung phones, indicating that smartphones are one of the devices using AI.
    2. **Galaxy S25 Series**: The document describes the Galaxy S25 series as featuring advanced, efficient AI image processing, which implies that this device uses AI.
    3. **Galaxy AI**: The document states that Galaxy AI is a set of generative AI tools available on newer Samsung phones, suggesting that the Galaxy S25 series and possibly other newer Samsung devices use AI.
    4. **Smart City Initiative**: The document provides an example of a government initiative using AI for real-time video analytics, advanced forensic investigation capabilities, and comprehensive operational intelligence. While it doesn't specify which devices are used, it implies that AI is used across various devices in this context.
    
    Therefore, the devices using AI mentioned in the document are:
    - Smartphones (Samsung)
    - Galaxy S25 Series
    - Galaxy AI (presumably available on newer Samsung phones)

